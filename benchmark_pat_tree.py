#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
PAT-tree Performance Benchmark Script
æ¸¬è©¦ä¸¦åˆ†æPAT-treeçš„æ€§èƒ½ç“¶é ¸
"""

import time
import psutil
import sys
from pathlib import Path
from typing import List, Dict
import json
import numpy as np

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.ir.index.pat_tree import PatriciaTree
from src.ir.text.chinese_tokenizer import ChineseTokenizer


class PerformanceBenchmark:
    """PAT-treeæ€§èƒ½åŸºæº–æ¸¬è©¦"""

    def __init__(self):
        self.results = {}
        self.process = psutil.Process()

    def load_test_documents(self, limit: int = 121) -> List[Dict]:
        """è¼‰å…¥æ¸¬è©¦æ–‡æª”"""
        print(f"ğŸ“„ è¼‰å…¥æ¸¬è©¦æ–‡æª” (limit={limit})...")
        preprocessed_file = project_root / 'data' / 'preprocessed' / 'cna_mvp_preprocessed.jsonl'

        documents = []
        with open(preprocessed_file, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i >= limit:
                    break
                if line.strip():
                    doc = json.loads(line)
                    documents.append({
                        'doc_id': doc.get('article_id', ''),
                        'content': doc.get('content', '')
                    })

        print(f"âœ“ è¼‰å…¥ {len(documents)} ç¯‡æ–‡æª”")
        return documents

    def measure_build_time(self, documents: List[Dict]) -> Dict:
        """æ¸¬é‡å»ºæ§‹æ™‚é–“"""
        print("\nğŸ”¨ æ¸¬è©¦PAT-treeå»ºæ§‹æ€§èƒ½...")

        tokenizer = ChineseTokenizer(engine='jieba')
        tree = PatriciaTree()

        # è¨˜éŒ„åˆå§‹è¨˜æ†¶é«”
        mem_before = self.process.memory_info().rss / 1024 / 1024

        # æ¸¬é‡å»ºæ§‹æ™‚é–“
        start_time = time.time()
        total_tokens = 0

        for doc in documents:
            tokens = tokenizer.tokenize(doc['content'])
            total_tokens += len(tokens)

            for token in tokens:
                tree.insert(token, doc_id=doc['doc_id'])

        build_time = time.time() - start_time

        # è¨˜éŒ„æœ€çµ‚è¨˜æ†¶é«”
        mem_after = self.process.memory_info().rss / 1024 / 1024
        mem_used = mem_after - mem_before

        stats = tree.get_statistics()

        result = {
            'build_time_sec': round(build_time, 2),
            'tokens_per_sec': int(total_tokens / build_time),
            'memory_mb': round(mem_used, 2),
            'total_terms': stats['total_terms'],
            'unique_terms': stats['unique_terms'],
            'compression_ratio': round(stats['compression_ratio'], 2)
        }

        print(f"âœ“ å»ºæ§‹æ™‚é–“: {result['build_time_sec']}ç§’")
        print(f"  è™•ç†é€Ÿåº¦: {result['tokens_per_sec']:,} tokens/sec")
        print(f"  è¨˜æ†¶é«”ä½¿ç”¨: {result['memory_mb']} MB")
        print(f"  å£“ç¸®ç‡: {result['compression_ratio']}x")

        return tree, result

    def measure_query_performance(self, tree: PatriciaTree) -> Dict:
        """æ¸¬é‡æŸ¥è©¢æ€§èƒ½"""
        print("\nğŸ” æ¸¬è©¦æŸ¥è©¢æ€§èƒ½...")

        # æ¸¬è©¦prefix queries
        test_prefixes = ["å°", "ä¸­", "ç¾", "ç¶“", "æ”¿", "ç§‘", "æ•™", "æ–‡", "è³‡", "æ–°"]

        prefix_times = []
        for prefix in test_prefixes:
            start = time.time()
            results = tree.starts_with(prefix)
            elapsed = (time.time() - start) * 1000  # ms
            prefix_times.append(elapsed)
            print(f"  prefix='{prefix}': {elapsed:.2f}ms ({len(results)} matches)")

        # æ¸¬è©¦keyword extraction
        methods = ['tfidf', 'frequency', 'combined']
        extraction_times = {}

        for method in methods:
            start = time.time()
            keywords = tree.extract_keywords(top_k=20, method=method)
            elapsed = (time.time() - start) * 1000
            extraction_times[method] = round(elapsed, 2)
            print(f"  {method}: {elapsed:.2f}ms")

        result = {
            'prefix_search': {
                'mean_ms': round(np.mean(prefix_times), 2),
                'p50_ms': round(np.percentile(prefix_times, 50), 2),
                'p95_ms': round(np.percentile(prefix_times, 95), 2),
                'p99_ms': round(np.percentile(prefix_times, 99), 2),
            },
            'keyword_extraction': extraction_times
        }

        return result

    def measure_visualization(self, tree: PatriciaTree) -> Dict:
        """æ¸¬é‡è¦–è¦ºåŒ–æ€§èƒ½"""
        print("\nğŸ¨ æ¸¬è©¦è¦–è¦ºåŒ–æ€§èƒ½...")

        # Test full tree
        start = time.time()
        viz_data = tree.visualize_tree(max_nodes=100, prefix="")
        time_full = (time.time() - start) * 1000

        # Test with prefix
        start = time.time()
        viz_data = tree.visualize_tree(max_nodes=50, prefix="å°")
        time_prefix = (time.time() - start) * 1000

        print(f"  Full tree (100 nodes): {time_full:.2f}ms")
        print(f"  With prefix (50 nodes): {time_prefix:.2f}ms")

        return {
            'full_tree_ms': round(time_full, 2),
            'prefix_tree_ms': round(time_prefix, 2)
        }

    def generate_report(self, results: Dict):
        """ç”Ÿæˆæ€§èƒ½å ±å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š PAT-tree æ€§èƒ½æ¸¬è©¦å ±å‘Š")
        print("=" * 60)

        print("\n### å»ºæ§‹æ€§èƒ½ (Build Performance)")
        build = results['build']
        print(f"  å»ºæ§‹æ™‚é–“: {build['build_time_sec']} ç§’")
        print(f"  è™•ç†é€Ÿåº¦: {build['tokens_per_sec']:,} tokens/sec")
        print(f"  è¨˜æ†¶é«”ä½¿ç”¨: {build['memory_mb']} MB")
        print(f"  å£“ç¸®ç‡: {build['compression_ratio']}x")

        print("\n### æŸ¥è©¢æ€§èƒ½ (Query Performance)")
        query = results['query']
        print(f"  Prefix Search (å¹³å‡): {query['prefix_search']['mean_ms']} ms")
        print(f"  Prefix Search (P95): {query['prefix_search']['p95_ms']} ms")

        print("\n  Keyword Extraction:")
        for method, time_ms in query['keyword_extraction'].items():
            print(f"    {method}: {time_ms} ms")

        print("\n### è¦–è¦ºåŒ–æ€§èƒ½ (Visualization)")
        viz = results['visualization']
        print(f"  Full tree: {viz['full_tree_ms']} ms")
        print(f"  Prefix tree: {viz['prefix_tree_ms']} ms")

        print("\n### æ€§èƒ½è©•åˆ† (Performance Score)")
        # è¨ˆç®—ç¶œåˆåˆ†æ•¸ (è¶Šä½è¶Šå¥½)
        build_score = build['build_time_sec'] / 30  # ç›®æ¨™30ç§’
        query_score = query['prefix_search']['mean_ms'] / 10  # ç›®æ¨™10ms
        memory_score = build['memory_mb'] / 100  # ç›®æ¨™100MB

        total_score = (build_score + query_score + memory_score) / 3

        if total_score < 0.8:
            grade = "A (å„ªç§€)"
        elif total_score < 1.2:
            grade = "B (è‰¯å¥½)"
        elif total_score < 1.5:
            grade = "C (å¯æ¥å—)"
        else:
            grade = "D (éœ€å„ªåŒ–)"

        print(f"  ç¶œåˆè©•åˆ†: {grade}")

        print("\n" + "=" * 60)

        # Save report
        report_file = project_root / 'performance_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ“ è©³ç´°å ±å‘Šå·²å„²å­˜è‡³: {report_file}")

    def run(self):
        """åŸ·è¡Œå®Œæ•´æ€§èƒ½æ¸¬è©¦"""
        print("ğŸš€ PAT-tree æ€§èƒ½åŸºæº–æ¸¬è©¦")
        print("=" * 60)

        # Load documents
        documents = self.load_test_documents(limit=121)

        # Test build performance
        tree, build_results = self.measure_build_time(documents)
        self.results['build'] = build_results

        # Test query performance
        query_results = self.measure_query_performance(tree)
        self.results['query'] = query_results

        # Test visualization
        viz_results = self.measure_visualization(tree)
        self.results['visualization'] = viz_results

        # Generate report
        self.generate_report(self.results)


if __name__ == '__main__':
    benchmark = PerformanceBenchmark()
    benchmark.run()
