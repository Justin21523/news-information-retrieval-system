# 期中考完整擬答 *Midterm Exam Draft Answers*

**課程**：LIS5033 自動分類與索引 *Automatic Classification and Indexing*
**學期**：2024-2025
**學生**：[學號] [姓名]
**日期**：2025-11-12

---

## 題目一：嵌入式搜尋與通用搜尋引擎之比較

### 一、觀點陳述

嵌入式搜尋（*Embedded Search*）與通用搜尋引擎（*General-Purpose Search Engine*）的本質差異在於「範圍」與「脈絡」兩個維度。嵌入式搜尋聚焦於封閉領域（*Closed Domain*）內的深度檢索，系統擁有豐富的使用者脈絡資訊與結構化資料，能夠提供高度個人化的檢索體驗；而通用搜尋引擎則追求開放網際網路的廣度覆蓋，面對異質性極高的海量資料，必須在無脈絡或有限脈絡下提供普適性的檢索服務。若以醫療比喻，嵌入式搜尋如同深入了解病患病史的專科醫生，能夠針對特定問題提供精準診斷；通用搜尋引擎則像是家庭醫師，必須具備廣泛知識以應對各種未知狀況。兩者並非對立關係，而是在不同應用情境下的互補設計，共同構成現代資訊檢索生態系統的重要組成部分。

### 二、例證支持

#### 嵌入式搜尋的特徵與案例分析

嵌入式搜尋最顯著的特點是「範圍限定」（*Scope Limitation*）與「脈絡豐富」（*Rich Context*）。以 Facebook 搜尋為例，當使用者查詢「王小明的照片」時，系統能夠利用社交圖譜（*Social Graph*）中的好友關係、隱私設定、互動歷史等多維度脈絡資訊。檢索過程不僅匹配關鍵字，更整合使用者與「王小明」的親密度（互動頻率、共同好友數）、內容時效性（近期貼文優先）、媒體類型（精確過濾相簿內容），最終呈現高度個人化的結果排序。這種檢索體驗在通用搜尋引擎中難以達成，因為後者無法存取使用者的社交關係網路。

嵌入式搜尋的另一優勢是「結構化資料」（*Structured Data*）的深度利用。以電商平台 Amazon 為例，每件商品都具備明確的結構化欄位：品牌、價格、評分、庫存狀態、配送選項等。使用者查詢「15 吋筆記型電腦 500 美元以下」時，系統可以精確執行欄位過濾（*Field-based Filtering*）與多維度排序，整合使用者的瀏覽歷史、購物車內容、地理位置（影響配送選項），提供「為你推薦」的客製化結果。這種結構化檢索能力遠超過通用搜尋引擎對開放網頁的理解深度。

「即時性」（*Real-time Indexing*）也是嵌入式搜尋的關鍵優勢。Twitter 使用者期待發布推文後數秒內即可被搜尋到，這要求索引系統支援高速增量更新（*Incremental Indexing*）。相較之下，Google 對新網頁的索引週期可能長達數小時甚至數天，因為通用搜尋引擎必須處理每日新增的數十億網頁，無法對每個網站提供毫秒級的即時索引。

#### 通用搜尋引擎的特徵與挑戰

通用搜尋引擎的核心挑戰在於「異質性」（*Heterogeneity*）與「無脈絡」（*Context-free*）。當使用者在 Google 查詢「蘋果」時，系統必須判斷這是指「水果」、「蘋果公司」還是「蘋果日報」，但查詢本身不包含足夠的脈絡線索。Google 採用的策略是依賴「大眾智慧」（*Wisdom of Crowds*）：透過 PageRank 演算法分析網頁的反向連結結構，假設被更多權威網站引用的頁面更相關；透過使用者行為信號（*User Engagement Signals*）如點擊率（CTR）、停留時間、返回率，學習哪些結果更符合大多數使用者的意圖。這種方法在處理熱門查詢時效果良好，但對長尾查詢（*Long-tail Query*）——那些極少被搜尋的罕見查詢——缺乏足夠的訓練資料。

通用搜尋引擎面臨的另一大挑戰是「品質控管」（*Quality Control*）。開放網際網路充斥著內容農場（*Content Farm*）、SEO 作弊、釣魚網站等低品質內容。Google 必須投入龐大資源開發反作弊演算法（如 Panda, Penguin 更新），建立網頁品質評分機制（*Page Quality Score*），並仰賴人工評測員（*Human Rater*）提供品質標註資料。相較之下，嵌入式搜尋的封閉環境提供天然的品質保證：Facebook 貼文來自使用者的社交圈、企業內部搜尋的文件經過審核、電商平台的商品資訊由賣家負責——這些都大幅降低了品質控管的負擔。

#### 技術架構的差異

從技術架構來看，兩者的索引規模與查詢最佳化策略存在顯著差異。Google 索引超過數千億網頁，必須採用分散式倒排索引（*Distributed Inverted Index*）跨數千台伺服器儲存，查詢處理採用多層快取（*Multi-tier Caching*）與近似演算法（*Approximation Algorithm*）以在次秒級回應。相較之下，單一電商網站的商品數量通常在百萬至千萬級，可以在單一資料中心內部署索引，有更多空間採用精確排序演算法與即時個人化計算。

排序策略的差異更為明顯。通用搜尋引擎以「內容相關性」（*Content Relevance*）與「權威性」（*Authority*）為主要排序依據，個人化因子的權重相對較低（避免過濾泡泡 *Filter Bubble*）。而嵌入式搜尋則大幅提高個人化權重，例如 LinkedIn 搜尋同時考慮職業網路距離、共同聯繫人、產業匹配度等社交信號，Netflix 搜尋片名時同步整合使用者的觀看歷史與評分偏好。

### 三、反例討論

儘管上述分析勾勒出兩者的典型特徵，但現實中存在許多模糊地帶，使得二分法的界線逐漸模糊。

#### 嵌入式搜尋面臨的挑戰

嵌入式搜尋的「範圍限制」在某些情境下反而成為缺點。當使用者在 Facebook 搜尋「新冠疫苗資訊」時，結果僅限於好友分享的貼文與公開粉絲專頁，這些內容的專業性與可信度遠不及醫學期刊或政府衛生機構網站。此時使用者需要跳出 Facebook，改用 Google 搜尋權威來源。這凸顯了嵌入式搜尋在「知識廣度」上的先天不足——封閉領域難以涵蓋人類知識的多樣性。

「冷啟動問題」（*Cold Start Problem*）是嵌入式搜尋個人化策略的阿基里斯腱。新註冊的使用者缺乏歷史資料，系統無法提供個人化排序，只能回退到通用排序（如按時間或熱門度）。這導致新使用者的檢索體驗與老用戶存在顯著落差，可能影響留存率。此外，過度個人化可能造成「同溫層效應」（*Echo Chamber*）：使用者只看到符合既有觀點的內容，缺乏多元觀點的接觸，長期可能強化偏見。

資料量的限制也影響機器學習模型的效能。嵌入式搜尋的訓練資料僅限於單一平台的互動記錄，相較於 Google 可利用全網際網路的點擊資料，可用的訓練樣本規模小數個量級。這使得嵌入式搜尋難以採用最先進的深度學習模型（如 BERT），只能使用較簡單的排序模型。

#### 通用搜尋引擎的演進

另一方面，通用搜尋引擎也在積極引入「個人化」與「脈絡理解」能力，逐漸縮小與嵌入式搜尋的差距。Google 自 2009 年起即提供個人化搜尋結果（*Personalized Search Results*），依據使用者的搜尋歷史、地理位置、裝置類型調整排序。當已登入使用者查詢「附近的餐廳」時，Google 整合 Google Maps 的位置服務、Google Reviews 的評價資料、使用者的 Gmail 信箱中的訂位記錄，提供高度客製化的推薦——這與嵌入式搜尋的體驗已相當接近。

「知識圖譜」（*Knowledge Graph*）的引入更是重大突破。當查詢「愛因斯坦」時，Google 不再只是回傳相關網頁連結，而是直接呈現結構化的知識卡片：出生日期、主要成就、相關人物等，這些資訊萃取自 Wikipedia, Wikidata 等結構化知識庫。這種「直接答案」（*Direct Answer*）的體驗類似於查詢企業內部知識庫，模糊了通用搜尋與嵌入式搜尋的界線。

「垂直搜尋」（*Vertical Search*）更是兩者融合的典型案例。Google Shopping, Google Flights, Google Scholar 都是針對特定領域的嵌入式搜尋，卻整合在通用搜尋引擎的介面中。使用者查詢「筆記型電腦」時，Google Shopping 提供類似 Amazon 的商品比價與規格篩選功能；查詢學術論文時，Google Scholar 提供引用追蹤與相關文獻推薦——這些都是嵌入式搜尋的特徵。

#### 混合模式的興起

實務中，許多系統採用「混合模式」（*Hybrid Approach*）兼顧兩者優勢。例如：

- **Google 站內搜尋**（`site:example.com`）：在通用搜尋引擎的基礎設施上執行嵌入式搜尋，既利用 Google 的爬蟲與索引技術，又限定範圍於單一網站。

- **企業搜尋平台**（如 Elasticsearch）：提供通用檢索引擎的核心能力（全文索引、多語言分析、分散式架構），但部署在封閉的企業內部網路，整合企業的權限系統與使用者目錄。

- **聯邦搜尋**（*Federated Search*）：同時查詢多個嵌入式搜尋來源（如同時搜尋公司的文件庫、郵件系統、專案管理工具），再整合結果排序——這試圖突破單一嵌入式搜尋的範圍限制，同時保留深度整合的優勢。

### 四、小結總結

嵌入式搜尋與通用搜尋引擎的區別，本質上反映了「深度」與「廣度」、「精準」與「涵蓋」的永恆權衡。嵌入式搜尋透過犧牲範圍來換取深度整合與個人化體驗，適合使用者已明確限定領域的檢索需求；通用搜尋引擎則透過犧牲精細脈絡來換取最大的知識涵蓋，適合探索未知資訊的開放式檢索。

然而，技術演進正在模糊這條界線。通用搜尋引擎透過個人化、知識圖譜、垂直搜尋等技術，逐漸具備嵌入式搜尋的深度；嵌入式搜尋則透過跨平台整合（如 OAuth 單一登入、API 互聯）、外部資料源引入（如嵌入 Google Maps），逐漸擴展廣度。未來的資訊檢索系統可能呈現「多層次混合架構」：底層是通用搜尋引擎的廣泛爬蟲與索引能力，中層是各領域的垂直搜尋與知識庫，上層是高度個人化的智慧助理——這將同時滿足使用者對「找到所有相關資訊」與「只看我需要的資訊」的雙重需求。

從資訊尋求行為（*Information Seeking Behavior*）的角度來看，理想的檢索系統應該無縫支援「探索」到「利用」的完整光譜：當使用者處於探索階段（Exploration），提供通用搜尋的廣度覆蓋；當逐漸聚焦需求後（Focusing），自動切換到垂直搜尋的深度挖掘；當需求完全明確後（Exploitation），提供個人化的直接答案。這種「適應性檢索系統」（*Adaptive Retrieval System*）是未來研究的重要方向，也是嵌入式搜尋與通用搜尋引擎融合的終極目標。

---

## 題目二：搜尋與瀏覽的資訊存取策略

### 一、觀點陳述

搜尋（*Searching*）與瀏覽（*Browsing*）是資訊存取（*Information Access*）的兩種基本策略，其核心差異在於「資訊需求的明確程度」與「認知負荷的分配」。搜尋是目標導向的主動尋找過程，使用者已具備明確的資訊需求並能將其轉化為查詢表達式，系統透過匹配與排序演算法直接導引使用者到達目標資訊，整個過程追求效率與精準性。相較之下，瀏覽是探索導向的被動接收過程,使用者的資訊需求模糊或尚未成形，透過視覺呈現的資訊結構（分類、標籤、推薦）觸發認知，在互動過程中逐步明確需求，整個過程強調偶然發現（*Serendipity*）與認知啟發。

若以地理導航比喻，搜尋如同使用 Google Maps 導航前往已知目的地——輸入地址、選擇路線、直達目標；瀏覽則像在陌生城市漫步探索——沒有特定目的地，跟隨有趣的街道與店家，在過程中發現意外驚喜。兩者並非互相排斥，而是互補策略：優秀的資訊系統應該同時支援精準搜尋與流暢瀏覽，讓使用者在「探索」與「利用」之間自由切換，適應資訊尋求過程中需求明確度的動態變化。

### 二、例證支持

#### 搜尋的特性與系統設計

搜尋策略的第一個特徵是「目標明確性」（*Goal Specificity*）。使用者通常已知要尋找的資訊類型，能夠構思查詢關鍵字。例如查詢「台灣 2024 年人口數」——這是典型的「已知項目搜尋」（*Known-item Search*），使用者預期存在確定的答案。另一種情境是「重新尋找」（*Re-finding*），如「上個月看過的那篇論文」，使用者記得資訊存在但忘記確切位置。這兩種情境都高度依賴搜尋功能，瀏覽策略效率極低。

從系統設計來看，搜尋介面的核心是「搜尋框」（*Search Box*）與「排序演算法」（*Ranking Algorithm*）。搜尋框通常置於頁面最顯著位置（如 Google 首頁），提供自動完成（*Auto-completion*）與拼寫校正（*Spell Correction*）降低查詢門檻。進階搜尋功能支援布林運算子（AND, OR, NOT）、欄位限定（如 `title:機器學習`）、日期範圍等精確控制。排序演算法決定結果呈現順序，網頁搜尋採用 PageRank 等權威性排序，電商搜尋則混合相關性、銷量、評價、個人化偏好等多重信號。

搜尋策略要求使用者承擔較高的「認知負荷」（*Cognitive Load*）——必須將資訊需求轉換為關鍵字，這涉及詞彙選擇、同義詞判斷、適當的抽象層次。對專業領域查詢，還需掌握領域術語。例如醫學文獻檢索，一般使用者可能查「肚子痛」，醫學專業人員則查「acute abdominal pain」或具體疾病的 MeSH 術語。這種「詞彙鴻溝」（*Vocabulary Gap*）是搜尋策略的主要障礙，也是查詢擴展（*Query Expansion*）等技術試圖解決的問題。

搜尋策略優先「精確率」（*Precision*）而非「召回率」（*Recall*）。使用者通常只查看前 1-2 頁結果（約 10-20 筆），因此排序演算法必須確保最相關的結果出現在前列。這與專業檢索不同——專利檢索或醫學系統性文獻回顧需要高召回率，不能遺漏任何相關文件。

#### 瀏覽的特性與系統設計

瀏覽策略的核心是「探索性」（*Exploratory*）與「視覺驅動」（*Visually-driven*）。使用者的典型心態是「我想看看有什麼」而非「我要找特定東西」。例如 Netflix 使用者打開 App 並非要找特定影片，而是瀏覽「熱門推薦」、「繼續觀看」、「因為你看過 XX」等分類，透過海報視覺吸引做出選擇。Pinterest 更是極致的瀏覽體驗——使用者以視覺瀑布流（*Visual Waterfall*）無限捲動圖片,透過點選感興趣的圖片逐步深入探索。

瀏覽系統的設計重點在「資訊架構」（*Information Architecture*）與「視覺呈現」（*Visual Presentation*）。階層式分類（*Hierarchical Classification*）是最傳統的瀏覽結構，例如電商網站的商品分類：電子產品 → 電腦 → 筆記型電腦 → 遊戲筆電。使用者透過逐層點選縮小範圍，過程中瀏覽每層的選項，同時建立對商品空間的心智模型（*Mental Model*）。

「分面瀏覽」（*Faceted Browsing*）是更進階的設計，允許使用者從多個維度同時篩選。例如 Airbnb 搜尋住宿，可同時選擇「價格範圍」、「房型」、「設施（WiFi, 停車場）」、「評分」等多個面向，系統即時更新符合條件的結果數量。這種設計比單一階層更靈活，使用者可以先選擇最在意的維度，再逐步增加限制條件。

「推薦系統」（*Recommender System*）是個人化瀏覽的核心技術。協同過濾（*Collaborative Filtering*）基於「喜歡這個的人也喜歡那個」原則，內容基礎過濾（*Content-based Filtering*）則分析項目屬性的相似性。Amazon 的「Customers who bought this item also bought」、YouTube 的「推薦影片」都是引導使用者持續瀏覽的設計。這些推薦不需使用者主動查詢，系統被動推送,大幅降低認知負荷。

瀏覽策略的另一優勢是「偶然發現」（*Serendipity*）。使用者可能遇到原本不知道存在的資訊，觸發新的興趣或解決未曾預見的問題。圖書館的實體書架天然支援瀏覽：讀者尋找特定書籍時，視線掃過鄰近書籍的書背,可能被意外標題吸引——這種偶然性在搜尋介面難以重現，因為搜尋僅回傳匹配查詢的結果。

#### 兩種策略的認知心理學基礎

從認知心理學角度分析，搜尋是「由上而下」（*Top-down*）的資訊處理：使用者大腦中已有目標表徵,外部搜尋僅是執行匹配。瀏覽則是「由下而上」（*Bottom-up*）的處理：外部刺激（視覺、文字）觸發認知反應,使用者在互動中逐步形成目標。

Marchionini (1995) 的資訊尋求模型指出,資訊需求的演變過程通常是：**模糊需求 → 瀏覽探索 → 逐漸聚焦 → 精確搜尋**。例如大學生撰寫「機器學習」報告：
1. **初期**：對主題陌生,瀏覽 Wikipedia、教科書目錄、課程大綱,建立基本理解
2. **中期**：確定關注「監督式學習」子主題,瀏覽相關章節,發現關鍵概念
3. **後期**：需要特定演算法細節,精確搜尋「random forest algorithm」、「gradient boosting」

這顯示優秀系統應支援「策略轉換」（*Strategy Switching*）:初期提供豐富的瀏覽入口,中期提供搜尋+瀏覽混合介面,後期提供進階搜尋功能。

### 三、反例討論

儘管上述分析突顯兩種策略的典型特徵,但實務中的界線遠比理論模型模糊,且各自存在明顯限制。

#### 搜尋策略的失效情境

當使用者缺乏「領域知識」（*Domain Knowledge*）時,搜尋策略效能大幅下降。初學者可能不知道正確術語——查「電腦跑很慢」而非專家使用的「disk I/O bottleneck」或「memory leak」——導致檢索結果品質低落。更糟的情況是「不知道不知道」（*Unknown Unknowns*）:使用者無法搜尋自己不知道存在的概念。例如學習程式設計的新手可能不知道「設計模式」（*Design Pattern*）這個概念的存在,自然無法搜尋相關資料,只能透過瀏覽教材時偶然發現。

「詞彙鴻溝」（*Vocabulary Mismatch*）是搜尋的阿基里斯腱。使用者的查詢詞彙與文件作者使用的術語不匹配時,相關文件可能完全無法被檢索。例如醫學領域,同一概念可能有多種表達:「心臟病發作」vs.「心肌梗塞」vs.「myocardial infarction」vs.「MI」。雖然查詢擴展、同義詞詞典等技術可部分緩解,但根本問題仍然存在。

搜尋策略也不適合「模糊需求」（*Vague Needs*）情境。當使用者只有模糊的資訊需求——如「我想學點設計相關的東西」——很難構思有效查詢。強行搜尋「設計」會得到海量異質結果（平面設計、建築設計、軟體設計...）,反而增加篩選負擔。此時瀏覽策略更有效:先進入設計相關的平台（如 Behance, Dribbble）,透過視覺瀏覽作品逐步發現興趣點。

#### 瀏覽策略的限制與挑戰

瀏覽策略的最大問題是「效率低落」（*Inefficiency*）。當使用者已知明確目標時,透過分類層層點選遠不如直接搜尋快速。例如在電商網站尋找特定型號商品「Sony WH-1000XM5」,若依分類瀏覽:電子產品 → 音訊 → 耳機 → 頭戴式 → Sony → 型號選擇,可能需要點選 5-6 次;直接搜尋型號僅需 1 次操作。這種效率差距在大型資訊空間（數百萬商品）更為顯著。

「資訊過載」（*Information Overload*）是瀏覽介面的常見問題。當呈現選項過多,使用者陷入「選擇困難」（*Choice Paralysis*）。心理學研究顯示,選項超過 7±2 個時認知負荷顯著增加。Netflix 雖提供上萬部影片,但若無良好的分類與推薦,使用者可能花費大量時間瀏覽卻無法做出選擇——這種「瀏覽疲勞」（*Browsing Fatigue*）反而降低滿意度。

瀏覽的「被動性」（*Passiveness*）限制了使用者的控制感。推薦系統決定呈現內容,使用者只能在既有選項中挑選,無法主動探索系統未推薦的內容。這可能造成「過濾泡泡」（*Filter Bubble*）:推薦演算法基於歷史行為推送相似內容,使用者接觸的資訊範圍逐漸窄化。例如 YouTube 演算法可能不斷推薦同類政治立場的影片,強化使用者既有觀點,缺乏多元視角。

分類系統的「人為限制」也是瀏覽策略的弱點。階層式分類要求每個項目歸屬單一路徑,但現實中許多項目具有多重屬性。例如「智慧手錶」可以歸類於「智慧裝置」或「穿戴配件」,不同使用者可能從不同路徑尋找,若分類設計不當會造成找不到目標的挫折感。這也是分面瀏覽興起的原因——它允許多維度交叉,但設計複雜度也隨之上升。

#### 搜尋與瀏覽的混合實踐

實務系統設計揭示,最佳策略是提供「無縫整合」（*Seamless Integration*）的混合介面,讓使用者根據當下需求自由選擇或切換策略。

**Amazon 的混合設計**是經典範例:
- **搜尋優先**:搜尋框置於頁首最顯著位置,支援自動完成
- **分類瀏覽**:左側提供商品分類樹,支援逐層深入
- **分面篩選**:搜尋結果頁提供品牌、價格、評分等多維度篩選器
- **推薦瀏覽**:「根據瀏覽記錄推薦」、「購買此商品的顧客也購買」等推薦區塊

這種設計讓使用者可以:
1. 先搜尋大類別（如「筆記型電腦」）
2. 瀏覽搜尋結果,透過分面篩選縮小範圍
3. 點選特定商品後,瀏覽相關推薦發現替代選項
4. 若不滿意,再修改搜尋關鍵字重新搜尋

**圖書館 OPAC 系統**的演進也反映這種趨勢:
- 傳統 OPAC:僅提供書目搜尋（title, author, ISBN）
- 現代 Discovery System:整合搜尋框、分類瀏覽、標籤雲、視覺化書架、推薦書單等多重入口

**學術搜尋（Google Scholar, PubMed）**的混合策略:
- 提供精確的布林搜尋與欄位限定（專業使用者）
- 同時提供「相關文獻」推薦（引用關係圖譜）
- 支援依年份、期刊、作者等面向瀏覽

### 四、小結總結

搜尋與瀏覽並非二元對立,而是資訊尋求光譜的兩端,反映使用者需求明確度的連續變化。現代資訊系統的設計哲學應該是「適應性」（*Adaptiveness*）:系統偵測使用者當前的需求狀態,自動或半自動地推薦適合的存取策略。

從「資訊覓食理論」（*Information Foraging Theory*）來看,使用者的行為類似動物覓食:當環境資訊豐富（清楚知道目標位置）時,採取「直線進攻」策略（搜尋）;當環境不明朗時,採取「區域探索」策略（瀏覽）。優秀系統應提供清晰的「資訊氣味」（*Information Scent*）——透過標題、摘要、縮圖、麵包屑導航等線索,讓使用者判斷是否接近目標,決定繼續深入或轉換路徑。

未來的發展趨勢包含:

1. **對話式介面**（*Conversational Interface*）:ChatGPT 等 LLM 模糊了搜尋與瀏覽的界線。使用者可以先提出模糊問題（「我想學機器學習」）,系統回覆概覽與子主題介紹（類似瀏覽）;再逐步深入特定主題（「詳細說明監督式學習」）,系統提供精確答案（類似搜尋）。整個過程是流暢的多輪對話。

2. **探索式搜尋介面**（*Exploratory Search UI*）:提供視覺化的搜尋結果組織（如文件群集、主題地圖）,讓使用者在搜尋結果中瀏覽,發現預期外的相關主題。

3. **情境感知推薦**（*Context-aware Recommendation*）:系統分析使用者當前任務（工作研究 vs. 休閒娛樂）、時間（通勤時段 vs. 深夜）、裝置（手機 vs. 桌機）,自動調整介面呈現偏向搜尋或瀏覽。

4. **混合實境導航**（*Mixed Reality Navigation*）:AR/VR 技術可能創造新型態的資訊空間瀏覽體驗,使用者在虛擬知識空間中「漫步」,同時保有隨時啟動搜尋的能力。

資訊系統設計的終極目標是「透明化」（*Transparency*）——使用者專注於任務本身,而非糾結於該用搜尋還是瀏覽。就像日常生活中,我們使用 Google Maps 時,有時直接搜尋地址,有時放大地圖瀏覽周遭,有時依賴推薦的「附近餐廳」——我們不會刻意區分這些策略,只是自然地使用最直覺的方式達成目標。優秀的資訊系統應該達到相同的直覺性與流暢性。

---

## 題目三：資訊檢索評估指標的應用

### 一、觀點陳述

資訊檢索系統的評估是一個多維度、脈絡依賴（*Context-dependent*）的複雜問題,不存在單一「最佳」指標能適用所有情境。精確率（*Precision*）、召回率（*Recall*）、平均平均精確率（*MAP, Mean Average Precision*）、標準化折損累積增益（*nDCG, Normalized Discounted Cumulative Gain*）等經典指標,各自從不同角度衡量檢索效能,反映不同的使用者需求與應用場景。

評估指標的選擇本質上是「價值判斷」（*Value Judgement*）:何種檢索表現被視為「優秀」取決於應用目標。網頁搜尋引擎追求前幾筆結果的高精確率,因為使用者通常只查看第一頁;專利檢索系統則追求高召回率,因為遺漏任何相關專利可能導致法律風險;推薦系統關注整體排序品質與多樣性,避免使用者體驗單調。因此,IR 系統評估應該採取「指標組合」（*Metric Suite*）策略:選擇 2-3 個主要指標涵蓋不同面向,輔以使用者研究驗證指標與實際滿意度的相關性,最終目標是建立與業務目標一致的評估框架。

### 二、例證支持

#### 基礎指標:Precision 與 Recall

精確率與召回率是 IR 評估的基石,源自二元分類任務:

```
Precision = |相關且被檢索| / |被檢索的文件總數|
Recall = |相關且被檢索| / |全部相關文件數|
```

**Precision 的應用情境**:當使用者**時間受限**且**只查看少量結果**時,Precision 是關鍵指標。網頁搜尋使用者平均僅查看前 10 筆結果,Google 必須確保這 10 筆的高相關性,因此 **Precision@10** 是核心指標。類似地,行動裝置螢幕限制使得前 5 筆更為關鍵（**Precision@5**）。電商推薦系統在首頁展示 20 件商品,這 20 件的點擊率直接影響營收,因此 **Precision@20** 是 A/B 測試的主要指標。

**Recall 的應用情境**:當**遺漏相關文件有嚴重後果**時,Recall 成為優先考量。專利檢索（*Patent Search*）是典型案例:企業申請專利前必須確認無相似既有專利（*Prior Art Search*）,若漏掉任何相關專利,申請可能被駁回或未來面臨侵權訴訟。此時寧可過度檢索（低 Precision）,也不能遺漏（高 Recall 優先）。醫學系統性文獻回顧（*Systematic Literature Review*）同樣要求高召回率:研究者需要綜覽所有相關研究以避免選擇偏誤（*Selection Bias*）,PubMed 等醫學資料庫提供複雜的布林查詢語法,支援高召回率檢索。

**Precision-Recall Trade-off**:兩者通常存在反向關係。提高檢索門檻（如增加 AND 運算子）可提升 Precision 但降低 Recall;降低門檻（如使用 OR）則相反。F-measure 試圖平衡兩者:

```
F1 = 2 × (Precision × Recall) / (Precision + Recall)
F_β = (1+β²) × (Precision × Recall) / (β² × Precision + Recall)
```

**F₁** 給予兩者相同權重; **F₂** 更重視 Recall（β=2）; **F₀.₅** 更重視 Precision（β=0.5）。實務中可根據應用需求調整 β 值。

#### 排序品質指標:Average Precision (AP) 與 MAP

Precision/Recall 的問題在於未考慮**排序位置**（*Ranking Position*）。假設兩系統都檢索 10 筆文件,其中 5 筆相關:
- **系統 A**:相關文件位於第 1, 2, 3, 4, 5 位
- **系統 B**:相關文件位於第 6, 7, 8, 9, 10 位

兩者 Precision@10 與 Recall 相同,但系統 A 明顯更優秀（使用者更早看到相關文件）。Average Precision (AP) 解決此問題:

```
AP = (Σ [Precision@k × rel(k)]) / |相關文件總數|
```

其中 `k` 是排序位置,`rel(k)` 是第 k 位的相關性（1=相關, 0=不相關）。AP 對排序位置敏感:相關文件排序越前,AP 越高。

**範例計算**:假設檢索 10 筆文件,相關性為 [1, 0, 1, 1, 0, 1, 0, 0, 0, 0]
```
k=1: Precision=1/1=1.0, rel=1 → 1.0
k=3: Precision=2/3=0.67, rel=1 → 0.67
k=4: Precision=3/4=0.75, rel=1 → 0.75
k=6: Precision=4/6=0.67, rel=1 → 0.67
AP = (1.0 + 0.67 + 0.75 + 0.67) / 4 = 0.77
```

**Mean Average Precision (MAP)** 是多個查詢的 AP 平均值,常用於評估系統整體效能:

```
MAP = (Σ AP_q) / |查詢總數|
```

MAP 是 TREC（Text REtrieval Conference）等國際評測競賽的標準指標,被視為「單一數字總結」（*Single-figure Summary*）系統效能。**優點**:整合 Precision 與排序位置,易於比較不同系統。**缺點**:僅考慮二元相關性（相關/不相關）,未區分不同程度的相關。

#### 分級相關性指標:nDCG

真實世界的相關性往往是**多級的**（*Graded Relevance*）而非二元。搜尋「機器學習教學」時:
- **非常相關**（3 分）:頂尖大學的完整課程網站
- **相關**（2 分）:部落格的入門教學文章
- **部分相關**（1 分）:提及機器學習但非教學為主的文章
- **不相關**（0 分）:完全無關內容

**Discounted Cumulative Gain (DCG)** 同時考慮相關程度與排序位置:

```
DCG@k = Σ (2^rel_i - 1) / log₂(i+1)
```

其中 `rel_i` 是第 i 位文件的相關等級（0-3）。分母 `log₂(i+1)` 實現「位置折損」（*Position Discount*）:排序越後權重越低,反映使用者注意力隨位置下降的事實。

**Normalized DCG (nDCG)** 正規化至 [0,1] 區間,便於跨查詢比較:

```
nDCG@k = DCG@k / IDCG@k
```

其中 **IDCG**（*Ideal DCG*）是理想排序（所有相關文件依相關程度遞減排列）的 DCG 值。

**範例計算**:檢索 5 筆文件,相關等級為 [3, 2, 0, 1, 2]
```
DCG@5 = (2³-1)/log₂(2) + (2²-1)/log₂(3) + (2⁰-1)/log₂(4) + (2¹-1)/log₂(5) + (2²-1)/log₂(6)
      = 7/1 + 3/1.58 + 0/2 + 1/2.32 + 3/2.58
      = 7 + 1.90 + 0 + 0.43 + 1.16 = 10.49

理想排序 [3, 2, 2, 1, 0]:
IDCG@5 = 7/1 + 3/1.58 + 3/2 + 1/2.32 + 0/2.58
       = 7 + 1.90 + 1.5 + 0.43 + 0 = 10.83

nDCG@5 = 10.49 / 10.83 = 0.97
```

**nDCG 的應用**:
- **搜尋引擎**:區分權威來源（政府、大學）與一般網站
- **推薦系統**:區分暢銷商品（高相關）與冷門商品（低相關）
- **問答系統**:區分完整答案（3 分）、部分答案（1 分）、無答案（0 分）

**優點**:最貼近真實使用情境,支援多級相關性。**缺點**:需要人工標註分級相關性,成本較二元標註高 3-5 倍。

#### 其他重要指標

**Reciprocal Rank (RR)** 與 **Mean Reciprocal Rank (MRR)**:
```
RR = 1 / rank(第一個相關文件位置)
MRR = 平均(所有查詢的 RR)
```

適用於「只需一個答案」的情境,如問答系統、導航查詢（*Navigational Query*）。例如查詢「Facebook」,使用者只要第一筆是 facebook.com 即滿意,其他結果無關緊要。

**Success@k** 或 **Hits@k**:
```
Success@k = 前 k 筆結果中至少有一個相關? (1 或 0)
```

適用於二元成功判斷,如前 5 筆中是否包含使用者要找的項目。

#### 案例分析:不同場景的指標選擇

| 應用場景 | 主要指標 | 原因 |
|---------|----------|------|
| 網頁搜尋（Google） | nDCG@10, Precision@5 | 使用者只看首頁,需區分優質來源 |
| 專利檢索 | Recall@100, F2 | 不能遺漏相關專利（法律風險） |
| 電商推薦 | nDCG@20, CTR | 需區分暢銷/冷門,最終看點擊率 |
| 問答系統 | MRR, Success@1 | 第一個答案正確即可 |
| 影像搜尋 | Precision@50, Recall@100 | 使用者會捲動較多結果 |
| 學術文獻 | MAP, Recall@50 | 需要涵蓋重要文獻,排序次之 |
| 新聞搜尋 | nDCG@10, Freshness | 時效性與相關性並重 |

### 三、反例討論

#### 指標的局限性與誤導

**單一指標的陷阱**:過度關注單一指標可能導致優化方向偏離實際目標。經典案例是「提升召回率至 100%」——只要回傳所有文件,Recall 必然達到 100%,但 Precision 趨近於零,系統毫無實用價值。類似地,只優化 Precision@1 可能讓系統僅回傳一筆超高信心結果,忽略其他潛在相關文件。

**MAP 的不穩定性**:MAP 對排序位置變動高度敏感。假設系統 A 和 B 的結果幾乎相同,僅有兩個相關文件交換位置:
```
系統 A: [相關, 不相關, 相關, ...] → AP = 0.83
系統 B: [不相關, 相關, 相關, ...] → AP = 0.72
```

兩者實質差異微小,但 MAP 差距 10%以上。這種不穩定性使得 MAP 在統計檢定時需要較大的樣本數才能達到顯著性。

**nDCG 的標註成本與主觀性**:分級相關性標註需要標註員深入理解文件內容,判斷相關程度。不同標註員對「非常相關」與「相關」的界線可能不同,導致標註者間一致性（*Inter-annotator Agreement*）降低。Kappa 係數常用於衡量一致性,但即使 Kappa=0.6（中等一致性）,標註噪音仍可能影響 nDCG 的可靠性。此外,分級標註的時間成本是二元標註的 3-5 倍,限制了可標註的資料量。

#### 離線指標與線上指標的落差

離線評估（*Offline Evaluation*）使用預先標註的測試集計算指標,優點是快速、可重現、成本低。但離線指標與真實使用者滿意度的相關性並非完美。Microsoft 的研究發現,提升 MAP 從 0.35 到 0.40（14% 改善）僅對應使用者滿意度提升 2-3%。這種落差源於:

1. **測試集偏誤**:標註資料通常覆蓋熱門查詢,長尾查詢（*Long-tail Query*）標註不足。系統在測試集表現優異,實際部署後長尾查詢效能可能下降。

2. **靜態 vs. 動態**:離線評估基於靜態文件集,但真實搜尋引擎面對動態更新的網頁。新聞搜尋需要即時索引當天新聞,測試集無法反映這種時效性需求。

3. **單次查詢 vs. 會話**:傳統 IR 評估獨立評估每個查詢,但真實使用者常進行「會話式搜尋」（*Session-based Search*）:查詢 → 點選結果 → 修改查詢 → 再次搜尋。會話層級的成功率（*Session Success Rate*）可能比單次查詢指標更重要。

**線上評估**（*Online Evaluation*）直接衡量使用者行為:
- **點擊率（CTR, Click-Through Rate）**:使用者點選結果的比例
- **停留時間（Dwell Time）**:點選後停留在頁面的時間（長停留暗示相關）
- **跳出率（Bounce Rate）**:快速返回搜尋結果頁（暗示不相關）
- **轉換率（Conversion Rate）**:電商場景中完成購買的比例
- **零點擊搜尋（Zero-click Search）**:搜尋結果頁直接提供答案,使用者無需點選

**A/B 測試**（*A/B Testing*）是線上評估的金標準:隨機分配使用者到新舊系統,比較上述指標的差異。但 A/B 測試成本高（需要真實流量）、週期長（需累積統計顯著樣本）、風險高（新系統可能損害使用者體驗）,無法用於早期研發階段。

**理想策略**:結合離線與線上評估:
1. **研發階段**:使用 MAP, nDCG 等離線指標快速迭代
2. **預上線測試**:小規模 A/B 測試驗證離線改善能轉化為線上收益
3. **上線後監控**:持續追蹤 CTR, 轉換率等業務指標
4. **回饋迴圈**:線上資料（點擊日誌）成為新的訓練/測試資料

#### 多樣性與新穎性的缺失

傳統 IR 指標關注「相關性」（*Relevance*）,忽略「多樣性」（*Diversity*）與「新穎性」（*Novelty*）。搜尋「Python」時,若前 10 筆結果都是 Python 程式語言的入門教學,即使相關性都很高,使用者體驗仍可能不佳——因為他可能在找 Python（蟒蛇）的生物資訊,或 Monty Python（喜劇團體）。

**α-nDCG** 修正 nDCG 以考慮多樣性:對已涵蓋的資訊面向,後續相同面向的文件價值打折。**Intent-aware Metrics** 假設每個查詢有多個可能意圖,評估系統是否涵蓋各意圖。

推薦系統更重視多樣性——若只推薦暢銷商品,雖然點擊率高（優化 Precision）,但使用者體驗單調,長期可能流失。**Intra-list Diversity** 指標衡量推薦清單內項目的異質程度。

### 四、小結總結

資訊檢索評估是「測量理論」與「實用主義」的平衡藝術。沒有「完美」的指標,每個指標都是特定假設下的簡化模型,適用特定情境但不具普適性。

**評估框架的建議實踐**:

1. **多指標組合**:同時報告至少 3 個指標,涵蓋不同面向
   - **主要指標**:依應用選擇（網頁搜尋用 nDCG@10,專利檢索用 Recall@100）
   - **補充指標**:Precision@5, MAP（提供不同視角）
   - **使用者指標**:線上 CTR, 停留時間（驗證實際滿意度）

2. **統計顯著性檢定**:使用 t-test, Wilcoxon signed-rank test 等檢定指標改善是否顯著,避免過度詮釋隨機波動。

3. **錯誤分析**（*Error Analysis*）:不僅看整體指標,深入分析失敗案例:
   - 哪些類型查詢效能差？（短查詢、長尾查詢、多義查詢）
   - 錯誤的根本原因？（詞彙鴻溝、排序錯誤、索引缺失）

4. **使用者研究**:定期進行使用者訪談或可用性測試,驗證指標改善確實轉化為體驗提升。有時指標下降但使用者滿意度上升——例如提供直接答案減少點擊率,但節省使用者時間。

5. **脈絡化詮釋**:相同指標在不同基準下意義不同。MAP 從 0.25 提升到 0.30（20% 改善）在學術競賽可能算普通,但在已高度優化的商業系統可能是重大突破。

**未來評估的挑戰與方向**:

- **神經模型的可解釋性**:深度學習排序模型（BERT, T5）效能優異但難以解釋,評估不只看最終指標,還需理解模型決策依據。

- **公平性評估**（*Fairness Metrics*）:檢索系統可能對特定人群（少數族裔、性別）存在偏見。公平性指標衡量不同群體是否得到平等的檢索效能。

- **可持續性評估**（*Sustainability*）:大型神經模型能耗高昂,需要權衡效能改善與環境成本。每點 nDCG 提升的碳排放成本是新興評估維度。

- **互動式評估**:傳統評估假設單次查詢,未來需評估多輪對話式檢索（如與 ChatGPT 對話）的效能。

最終,評估指標僅是手段,真正目標是「幫助使用者達成資訊尋求任務」。優秀的 IR 研究者不僅能計算指標,更能批判性思考指標背後的假設,在指標與真實需求之間建立有意義的連結。正如統計學家 George Box 的名言:「所有模型都是錯的,但有些是有用的」——評估指標亦然。

---

*（其他題目的完整擬答將以相同格式撰寫,包含四段式結構、豐富案例、批判性討論與總結。由於篇幅限制,此處展示前三題作為範例。實際考試時可依教師指定題目完整作答。）*

---

## 附錄:重要公式速查

### TF-IDF 權重計算
```
TF(t,d) = freq(t,d) / max_freq(d)
IDF(t) = log(N / df(t))
TF-IDF(t,d) = TF(t,d) × IDF(t)
```

### 餘弦相似度
```
sim(d1, d2) = (d1 · d2) / (|d1| × |d2|)
```

### Rocchio 演算法
```
Q_new = α×Q_orig + β×(Σ D_rel / |D_rel|) - γ×(Σ D_irrel / |D_irrel|)
典型參數: α=1.0, β=0.75, γ=0.15
```

### 評估指標
```
Precision = TP / (TP + FP)
Recall = TP / (TP + FN)
F1 = 2 × (P × R) / (P + R)
AP = Σ(Precision@k × rel(k)) / |相關文件數|
MAP = Σ(AP_q) / |查詢數|
DCG@k = Σ(2^rel_i - 1) / log₂(i+1)
nDCG@k = DCG@k / IDCG@k
```

---

**最後更新**：2025-11-12
**字數統計**：約 12,000 字（前三題完整擬答）
**建議考試時間**：每題 40-50 分鐘

**考試提醒**：
- ✅ 記得攜帶學生證、文具
- ✅ 可自備一張 A4 雙面手寫筆記
- ✅ 注意時間分配,每題預留 5 分鐘檢查
- ✅ 善用圖表輔助說明（系統架構圖、流程圖）
- ✅ 雙語術語以斜體標示（*English Term*）

**祝考試順利！**
