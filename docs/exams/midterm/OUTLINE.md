# 期中考答題大綱 *Midterm Exam Outline*

**課程**：LIS5033 自動分類與索引 *Automatic Classification and Indexing*
**學期**：2024-2025
**考試類型**：申論題（四段式寫作）

---

## 答題架構說明

### 四段式寫作格式

每題答案採用以下結構：

1. **觀點陳述** *(Thesis Statement)*
   - 明確表達立場
   - 簡述核心論點
   - 約 100-150 字

2. **例證支持** *(Supporting Evidence)*
   - 具體案例說明
   - 理論依據
   - 技術細節
   - 約 200-300 字

3. **反例討論** *(Counter-arguments)*
   - 考慮對立觀點
   - 分析限制條件
   - 特殊情境探討
   - 約 150-200 字

4. **小結總結** *(Conclusion)*
   - 整合正反觀點
   - 提出平衡看法
   - 未來展望
   - 約 100-150 字

---

## 題目一：嵌入式搜尋 vs. 通用搜尋引擎

### 題目完整描述
比較與對比「嵌入式搜尋」（如 Facebook 動態搜尋、部落格站內搜尋）與「通用搜尋引擎」（如 Google、Bing）在架構設計、檢索策略、使用者體驗等面向的異同。

### 大綱要點

#### 1. 觀點陳述
- **核心論點**：兩者本質差異在於「範圍」與「脈絡」
  - 嵌入式：封閉領域、已知脈絡、深度整合
  - 通用：開放領域、未知脈絡、廣度覆蓋
- **比喻**：專科醫生 vs. 家庭醫師

#### 2. 例證支持

**嵌入式搜尋特點**：
- ✅ 範圍限定（單一網站/平台）
- ✅ 結構化資料（已知欄位：作者、時間、標籤）
- ✅ 使用者脈絡（登入狀態、社交關係、瀏覽歷史）
- ✅ 即時性要求（新貼文立即可搜）
- ✅ 個人化排序（好友優先、互動記錄）

**案例分析 - Facebook 搜尋**：
- 查詢：「王小明的照片」
- 利用：社交圖譜、好友關係、隱私設定
- 排序：互動頻率、時間近期、標籤相關

**通用搜尋特點**：
- ✅ 範圍開放（整個網際網路）
- ✅ 異質性資料（多種格式、語言、品質）
- ✅ 匿名查詢（無使用者脈絡，或脈絡有限）
- ✅ 權威性排序（PageRank、引用關係）
- ✅ 詐騙/垃圾內容過濾

**案例分析 - Google 搜尋**：
- 查詢：「information retrieval」
- 考量：網頁權威性、反向連結、內容品質
- 排序：PageRank、TF-IDF、點擊率

#### 3. 反例討論

**嵌入式搜尋的挑戰**：
- ❌ 資料量小：難以訓練複雜模型
- ❌ 冷啟動問題：新使用者無個人化資料
- ❌ 過度個人化：資訊同溫層效應
- ❌ 範圍限制：無法跨平台搜尋

**通用搜尋的困難**：
- ❌ 品質控管：垃圾內容、SEO 作弊
- ❌ 脈絡缺失：無法理解使用者真實意圖
- ❌ 長尾查詢：罕見查詢缺乏訓練資料
- ❌ 隱私疑慮：個人化需要追蹤使用者

**模糊地帶**：
- Google 站內搜尋（`site:example.com`）
- 學術搜尋引擎（Google Scholar, PubMed）- 垂直搜尋引擎（購物、旅遊）

#### 4. 小結總結
- 兩者非對立，而是互補
- 趨勢：通用搜尋逐漸個人化（搜尋歷史、位置）
- 趨勢：嵌入式搜尋擴展範圍（跨平台整合）
- 未來：聯邦式搜尋（federated search）整合兩者優勢

---

## 題目二：搜尋 vs. 瀏覽

### 題目完整描述
分析「搜尋」（Searching）與「瀏覽」（Browsing）兩種資訊存取策略的適用情境、認知負荷、系統設計差異，並探討兩者如何互補。

### 大綱要點

#### 1. 觀點陳述
- **核心論點**：兩者反映不同的「資訊需求明確程度」
  - 搜尋：目標明確、主動尋找、已知需求
  - 瀏覽：探索性質、被動接收、未知需求
- **比喻**：Google 地圖導航 vs. 市區漫步

#### 2. 例證支持

**搜尋特性 *Searching***：
- ✅ **明確目標**：已知要找什麼（Known-item search）
- ✅ **關鍵字驅動**：使用者主動輸入查詢
- ✅ **精準性優先**：Precision > Recall
- ✅ **快速滿足**：最短路徑到達目標
- ✅ **認知負荷高**：需要構思查詢詞

**適用情境**：
- 查詢特定事實（「台灣人口數」）
- 重新尋找已知資源（「上次看的論文」）
- 專業檢索（法律條文、醫學文獻）

**系統設計**：
- 搜尋框顯著放置
- 自動完成建議
- 進階查詢語法（Boolean, 欄位限定）
- 排序演算法（relevance ranking）

**瀏覽特性 *Browsing***：
- ✅ **探索導向**：不確定要找什麼（Exploratory search）
- ✅ **視覺驅動**：依賴介面呈現引導
- ✅ **涵蓋性優先**：Recall > Precision
- ✅ **偶然發現**：Serendipity（意外收穫）
- ✅ **認知負荷低**：點選即可

**適用情境**：
- 學習新領域（「我想了解機器學習」）
- 靈感激發（Pinterest, Instagram）
- 消遣娛樂（YouTube 推薦影片）
- 購物探索（電商分類瀏覽）

**系統設計**：
- 階層式分類（taxonomy, facets）
- 推薦系統
- 相關項目推薦（「看過這個的人也看...」）
- 視覺化呈現（縮圖、預覽）

#### 3. 反例討論

**搜尋的限制**：
- ❌ 詞彙鴻溝（vocabulary mismatch）：使用者不知道正確術語
- ❌ 資訊需求模糊時無效
- ❌ 無法發現未知知識
- ❌ 需要較高資訊素養

**範例**：新手查「電腦跑很慢」vs. 專家查「disk I/O bottleneck」

**瀏覽的限制**：
- ❌ 效率低落：需要翻閱大量內容
- ❌ 資訊過載：選擇困難
- ❌ 被動性：受限於系統設計的分類
- ❌ 同溫層效應：推薦系統的偏見

**範例**：在圖書館分類架上找書 vs. 直接查書目系統

#### 4. 小結總結
- **互補設計**：優秀系統整合兩者
  - Amazon：搜尋框 + 分類選單 + 推薦
  - 圖書館 OPAC：書目查詢 + 分類瀏覽
- **轉換流程**：瀏覽 → 聚焦 → 搜尋
  - 初期瀏覽建立心智模型
  - 逐漸明確需求後轉為搜尋
- **未來趨勢**：
  - 對話式搜尋（ChatGPT）混合兩者
  - 探索式搜尋介面（exploratory search UI）
  - 個人化瀏覽路徑

---

## 題目三：布林檢索 vs. 排序檢索

### 題目完整描述
比較布林檢索模型（Boolean Retrieval Model）與排序檢索模型（Ranked Retrieval Model, 如 TF-IDF）的優缺點、適用場景及演進關係。

### 大綱要點

#### 1. 觀點陳述
- **核心論點**：從「精確匹配」到「模糊排序」的典範轉移
  - 布林：二元判斷（相關/不相關）、專業使用者
  - 排序：程度判斷（相關程度）、一般使用者
- **歷史脈絡**：法律/專利檢索 → 網頁搜尋

#### 2. 例證支持

**布林檢索特性**：
- ✅ **精確控制**：AND, OR, NOT 精確定義查詢範圍
- ✅ **可重現性**：相同查詢產生相同結果
- ✅ **高精確率**：適合專業檢索（高 Precision）
- ✅ **透明性**：使用者理解查詢邏輯

**技術細節**：
```
查詢：information AND retrieval AND NOT medical
結果：{doc1, doc5, doc9}（嚴格匹配）
```

**優點**：
- 專利檢索：需要涵蓋所有相關專利（高 Recall）
- 法律文件：精確查找特定條款
- 學術資料庫：複雜查詢組合

**限制**：
- ❌ 全有或全無：無法表達「部分相關」
- ❌ 結果數量不可控：可能 0 筆或 100 萬筆
- ❌ 學習門檻高：需要訓練使用者
- ❌ 詞彙敏感：拼寫錯誤導致查無資料

**排序檢索特性**：
- ✅ **使用者友善**：自然語言查詢
- ✅ **結果排序**：依相關程度排序
- ✅ **部分匹配**：匹配部分查詢詞也顯示
- ✅ **可調整**：Top-K 控制結果數量

**技術細節**：
```
查詢：information retrieval
結果：doc1 (score: 0.95), doc2 (0.87), doc3 (0.76), ...
TF-IDF + Cosine Similarity
```

**優點**：
- 網頁搜尋：數十億文件需排序
- 電商搜尋：依相關度推薦商品
- 容錯性：拼寫錯誤仍可找到相似結果

**限制**：
- ❌ 不透明：使用者不知排序依據
- ❌ 不可重現：演算法調整影響結果
- ❌ 精確率不保證：前幾筆可能不相關
- ❌ 計算成本高：需計算所有文件分數

#### 3. 反例討論

**布林檢索仍然重要**：
- PubMed（醫學文獻）：提供 Advanced Search
- 法律資料庫（Westlaw）：精確查詢為主
- 電商篩選器（價格區間、品牌）：布林邏輯

**排序檢索的挑戰**：
- SEO 作弊：內容農場操縱排序
- 同義詞問題：「汽車」vs.「轎車」
- 長查詢效能：10+ 詞彙計算成本高

**混合模式**：
- Google：布林過濾（語言、時間）+ 排序呈現
- 學術搜尋：先布林篩選領域，再 TF-IDF 排序
- 電商：分面瀏覽（faceted search）= 布林 + 排序

#### 4. 小結總結
- 非此即彼，而是分層設計
- 現代系統：布林作為後端過濾，排序作為前端呈現
- 趨勢：語意理解（BERT）超越統計排序
- 專業檢索仍需布林精確控制

---

## 題目四：索引建構策略

### 題目完整描述
討論建構倒排索引（Inverted Index）時的關鍵設計決策，包括分詞策略、停用詞處理、詞幹提取、索引壓縮等技術的取捨。

### 大綱要點

#### 1. 觀點陳述
- **核心論點**：索引設計是「空間-時間-品質」的三角平衡
  - 更完整索引 → 更高空間成本
  - 更快查詢 → 更多預處理時間
  - 更高品質 → 更複雜處理邏輯

#### 2. 例證支持

**決策一：分詞策略 *Tokenization***
- **英文**：依空格分詞 vs. N-gram
- **中文**：
  - 字元索引（unigram）：「資訊檢索」→ {資, 訊, 檢, 索}
  - 詞彙索引（word-based）：「資訊檢索」→ {資訊, 檢索}
  - 權衡：字元索引召回率高但精確率低，詞彙索引相反

**決策二：停用詞 *Stopwords***
- **移除**：減少索引大小、加速查詢
  - 英文：the, a, is, are
  - 中文：的、了、嗎、呢
- **保留**：支援詞組查詢
  - "to be or not to be"（莎士比亞名句）
  - "The Who"（樂團名稱）
- **建議**：保留但降低權重

**決策三：詞幹提取 *Stemming* / 詞形還原 *Lemmatization***
- **Stemming**：快速但粗糙
  - running, runs, ran → run
- **Lemmatization**：精確但慢
  - better → good
- **中文無此問題**，但有簡繁轉換
  - 簡體：信息检索
  - 繁體：資訊檢索
  - 建議：統一轉繁體或建立映射

**決策四：位置資訊 *Positional Information***
- **不儲存**：節省空間（50% 縮減）
  - 僅支援 Boolean AND/OR
- **儲存**：支援詞組查詢、鄰近查詢
  - "information retrieval"（詞組）
  - "information NEAR/5 retrieval"（5 個詞內）
  - 空間增加但功能性提升

**決策五：索引壓縮 *Index Compression***
- **技術**：
  - Gap encoding（差距編碼）
  - Variable byte encoding（變長位元組）
  - Gamma/Delta codes
- **效果**：壓縮至原始大小 20-30%
- **權衡**：解壓縮需要額外 CPU 時間

#### 3. 反例討論

**過度處理的風險**：
- Stemming 錯誤：「universal」→「univers」、「university」→「univers」（錯誤合併）
- 停用詞過濾損失：搜尋「vitamin C」時移除「C」
- 過度壓縮：解壓縮成為瓶頸

**不同領域的需求**：
- **學術文獻**：保留所有詞彙、支援複雜查詢
- **新聞搜尋**：即時性優先、壓縮空間
- **程式碼搜尋**：保留符號、大小寫敏感
- **電商**：商品名稱精確匹配、型號保留

#### 4. 小結總結
- 無「最佳」策略，依應用需求調整
- 建議：建立可配置的索引管線
- 實務：A/B testing 驗證決策影響
- 趨勢：神經網路索引（dense retrieval）減少工程調校

---

## 題目五：評估指標的選擇

### 題目完整描述
分析不同 IR 評估指標（Precision, Recall, MAP, nDCG）的適用場景、優缺點，以及如何根據應用需求選擇合適指標。

### 大綱要點

#### 1. 觀點陳述
- **核心論點**：「沒有最好的指標，只有最合適的指標」
  - 不同任務關注不同面向
  - 單一指標無法涵蓋所有需求
  - 需組合多個指標全面評估

#### 2. 例證支持

**指標一：Precision（精確率）**
```
Precision = |相關且檢索到| / |檢索到的總數|
```
- **適用**：使用者只看前幾筆結果
  - 網頁搜尋前 10 筆
  - 推薦系統展示商品
- **優點**：直觀易懂
- **缺點**：未考慮召回率

**指標二：Recall（召回率）**
```
Recall = |相關且檢索到| / |所有相關文件|
```
- **適用**：需要涵蓋所有相關文件
  - 專利檢索（不能漏掉任何相關專利）
  - 醫學文獻回顧（systematic review）
- **優點**：確保完整性
- **缺點**：需要已知所有相關文件（需 qrels）

**指標三：F-measure（F 分數）**
```
F1 = 2 × (Precision × Recall) / (Precision + Recall)
```
- **適用**：需要平衡 Precision 和 Recall
- **變體**：F₂（重視 Recall）、F₀.₅（重視 Precision）

**指標四：Average Precision（平均精確率）**
```
AP = Σ(Precision@k × rel(k)) / |相關文件數|
```
- **特點**：考慮排序位置
- **適用**：評估單一查詢的排序品質
- **優點**：一個數字總結排序效能

**指標五：MAP（平均平均精確率）**
```
MAP = Σ(AP_q) / |查詢數|
```
- **適用**：評估系統整體效能
- **業界標準**：TREC, NTCIR 等競賽
- **缺點**：對二元相關性（相關/不相關）敏感

**指標六：nDCG（標準化折損累積增益）**
```
DCG@k = Σ(2^rel_i - 1) / log₂(i + 1)
nDCG@k = DCG@k / IDCG@k
```
- **特點**：支援多級相關性（0, 1, 2, 3）
  - 非常相關 > 相關 > 部分相關 > 不相關
- **位置折損**：越後面的位置權重越低
- **適用**：
  - 搜尋引擎（區分不同程度相關）
  - 推薦系統（評估推薦品質）
- **優點**：最貼近真實使用情境
- **缺點**：需要分級相關性標註（成本高）

#### 3. 反例討論

**單一指標的陷阱**：
- **只看 Precision@10**：系統回傳 1 筆高相關文件 + 9 筆垃圾 → P@10 還不錯，但其實很糟
- **只看 Recall**：回傳所有文件 → Recall = 100%，但 Precision 趨近 0
- **MAP 的問題**：對排序前後變動敏感，不穩定

**案例分析**：
| 系統 | P@10 | Recall | MAP | nDCG@10 |
|------|------|--------|-----|---------|
| A    | 0.90 | 0.30   | 0.45| 0.78    |
| B    | 0.70 | 0.85   | 0.62| 0.71    |

- **網頁搜尋選 A**（使用者只看前幾筆）
- **專利檢索選 B**（需要高召回率）

**不同場景的優先級**：
- **電商搜尋**：nDCG > Precision（區分暢銷/冷門商品）
- **問答系統**：Success@1（第一筆答對即可）
- **影像搜尋**：Recall@100（使用者會往下捲動）

#### 4. 小結總結
- **建議策略**：同時報告多個指標
  - 主要指標：依應用選擇（MAP 或 nDCG）
  - 輔助指標：P@5, P@10, Recall
- **實務作法**：
  - 離線評估：MAP, nDCG
  - 線上評估：CTR, 停留時間, 轉換率
- **未來方向**：使用者滿意度建模（user satisfaction metrics）

---

## 題目六：查詢擴展技術

### 題目完整描述
說明查詢擴展（Query Expansion）技術如何改善檢索效能，比較 Rocchio 演算法、擬相關回饋、語意擴展等方法，並討論可能的風險。

### 大綱要點

#### 1. 觀點陳述
- **核心問題**：詞彙鴻溝（Vocabulary Mismatch）
  - 使用者查詢詞 ≠ 文件使用詞彙
  - 同義詞問題：「汽車」vs.「轎車」
  - 過度簡短查詢：平均 2-3 個詞
- **解決方案**：自動擴展查詢，加入相關詞彙

#### 2. 例證支持

**技術一：Rocchio 演算法**
```
Q_new = α×Q_orig + β×D_rel - γ×D_irrel
```
- **原理**：向相關文件靠近，遠離不相關文件
- **參數**：
  - α = 1.0（保留原查詢）
  - β = 0.75（相關文件權重）
  - γ = 0.0 或 0.15（不相關文件權重）
- **步驟**：
  1. 初始查詢取得結果
  2. 使用者標記相關/不相關
  3. 計算相關文件中心向量
  4. 生成新查詢向量
  5. 重新檢索

**技術二：擬相關回饋 *Pseudo-Relevance Feedback***
- **假設**：前 K 筆（如 10 筆）結果為相關
- **優點**：無需使用者標記，全自動
- **風險**：若前 K 筆不相關 → 查詢漂移（query drift）

**範例**：
```
原查詢：「蘋果產品」
前 10 筆：iPhone, MacBook, iPad...
擴展詞：{蘋果, 產品, iPhone, 蘋果公司, iOS, Mac}
```

**技術三：同義詞擴展**
- **詞庫擴展**：WordNet, 同義詞詞典
  - 「汽車」→ {轎車, 車輛, automobile, car}
- **共現擴展**：統計詞彙共現
  - 「機器學習」常與「深度學習」共現 → 加入擴展

**技術四：語意擴展（現代方法）**
- **Word2Vec / BERT**：語意相似詞
  - 查詢：「國王」
  - 擴展：{皇帝, 君主, 王室, 國家元首}
- **優點**：捕捉深層語意關係
- **缺點**：計算成本高

#### 3. 反例討論

**查詢漂移風險 *Query Drift***
- **案例**：
  ```
  原查詢：「Java 程式語言」
  若前 10 筆混入「Java 咖啡」
  擴展後：{Java, 咖啡, 星巴克, 印尼...}
  → 偏離原意
  ```

**過度擴展**：
- 加入太多擴展詞 → 噪音增加
- 建議：只取前 5-10 個高權重詞

**不適用場景**：
- **短查詢已精確**：「b1234567 學號」→ 無需擴展
- **專有名詞**：「新冠病毒」→ 不要擴展成其他疾病
- **符號查詢**：程式碼搜尋「String.indexOf()」

**效能問題**：
- 擴展後查詢變長 → 計算成本增加
- 需要權衡：改善程度 vs. 速度下降

#### 4. 小結總結
- 查詢擴展對「一般查詢」有 10-20% 改善
- **保守策略**：α = 1（保留原查詢），β = 0.5（輕微擴展）
- **實務建議**：
  - 先嘗試原查詢
  - 若結果不佳（少於 N 筆），再自動擴展
  - 提供「相關搜尋」建議，讓使用者選擇
- **未來方向**：神經檢索（dense retrieval）隱式處理擴展

---

## 題目七：分群演算法比較

### 題目完整描述
比較階層式分群（Hierarchical Clustering）與平面分群（Flat Clustering）在文件分群的應用，討論 K-means, Complete-link, Single-link 等演算法的特性。

### 大綱要點

#### 1. 觀點陳述
- **核心差異**：「階層結構」vs.「扁平分區」
  - 階層式：樹狀結構、多層次、不需預設 K
  - 平面式：單層分區、需預設 K、速度快
- **選擇依據**：資料特性、使用需求、計算資源

#### 2. 例證支持

**階層式分群 *Hierarchical Clustering***

**凝聚式 *Agglomerative*（由下而上）**：
1. 初始：每個文件為一個群集
2. 重複：合併最相似的兩個群集
3. 終止：直到剩下 K 個群集（或全部合併）

**分裂式 *Divisive*（由上而下）**：
1. 初始：所有文件在一個群集
2. 重複：分裂最異質的群集
3. 終止：直到達到 K 個群集

**連結方式 *Linkage***：
- **Single-link（單一連結）**：
  - 定義：兩群集最近的兩點距離
  - 特性：容易產生鏈狀群集（chaining）
  - 適合：狹長型資料分布

- **Complete-link（完全連結）**：
  - 定義：兩群集最遠的兩點距離
  - 特性：產生緊密、球狀群集
  - 適合：圓形分布資料

- **Group-average（群組平均）**：
  - 定義：兩群集所有點對的平均距離
  - 特性：平衡單一與完全連結
  - 最常用

**複雜度**：O(n³) 或 O(n² log n)（優化後）

**平面分群 *Flat Clustering***

**K-means 演算法**：
1. 隨機選擇 K 個中心點
2. 分配：每個文件分配到最近的中心
3. 更新：重新計算每個群集的中心
4. 重複 2-3 直到收斂

**特性**：
- ✅ 快速：O(n × K × I)，I 為迭代次數
- ✅ 可擴展：適合大規模資料
- ❌ 需預設 K
- ❌ 對初始值敏感
- ❌ 假設球狀群集

**改良方法**：
- **K-means++**：智慧初始化，避免局部最優
- **Mini-batch K-means**：使用樣本加速
- **Bisecting K-means**：結合階層概念

#### 3. 反例討論

**階層式的限制**：
- ❌ **計算成本**：大規模資料（百萬文件）不可行
- ❌ **不可逆**：一旦合併/分裂無法復原
- ❌ **對噪音敏感**：單一異常點影響整體結構

**K-means 的失效情境**：
- **非球形群集**：月牙形、甜甜圈形分布失效
- **不同大小群集**：偏向大小相近的群集
- **K 值選擇困難**：Elbow method 不明確時

**案例分析**：
```
資料：新聞文章 50,000 篇
需求：分為「政治、經濟、體育、娛樂...」等類別

選項 A：階層式（Complete-link）
- 優點：可視化樹狀圖、探索最佳 K
- 缺點：計算 50,000² 距離矩陣 → 記憶體爆炸

選項 B：K-means (K=10)
- 優點：30 秒完成、可處理大規模
- 缺點：需人工調整 K、可能需多次執行

建議：先用抽樣資料（5,000 篇）跑階層式，觀察最佳 K
      再用完整資料跑 K-means with K=最佳值
```

#### 4. 小結總結
- **小資料（< 10,000）**：階層式，探索性分析
- **大資料（> 100,000）**：K-means，效率優先
- **混合策略**：Bisecting K-means（兼顧兩者優點）
- **實務評估**：
  - 內部指標：Silhouette score, Davies-Bouldin index
  - 外部指標：若有標籤，用 Purity, NMI
- **未來方向**：密度分群（DBSCAN）、譜分群（Spectral Clustering）

---

## 考前準備檢核表

### 📖 理論複習
- [ ] 閱讀教科書對應章節
- [ ] 複習課堂投影片
- [ ] 理解核心公式（TF-IDF, Cosine similarity, Rocchio, nDCG）
- [ ] 準備具體案例（Google, Facebook, Amazon 等）

### ✍️ 寫作練習
- [ ] 練習四段式寫作（每題 30 分鐘）
- [ ] 準備雙語術語對照表
- [ ] 練習手繪示意圖（索引結構、系統架構）
- [ ] 模擬考古題（若有）

### 📊 圖表準備
- [ ] 倒排索引結構圖
- [ ] Boolean 查詢處理流程
- [ ] VSM 向量空間示意圖
- [ ] Rocchio 演算法示意圖
- [ ] 階層式分群樹狀圖

### 🧠 記憶重點
- [ ] 各模型優缺點對照表
- [ ] 演算法複雜度
- [ ] 評估指標公式
- [ ] 經典案例與數據（PageRank, TREC 競賽等）

---

**最後更新**：2025-11-12
**預估答題時間**：每題 30-40 分鐘
**建議總複習時間**：2-3 週

**祝考試順利！**
