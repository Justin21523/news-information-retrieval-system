# 期末專案提案：中文新聞智能檢索系統

**專案名稱**：CNIRS - 中文新聞智能檢索系統
**英文名稱**：Chinese News Intelligent Retrieval System (CNIRS)

**課程**：LIS5033 自動分類與索引
**學期**：2024-2025
**團隊成員**：[學號] [姓名]（個人專案）
**提案日期**：2025-01-13

---

## 1. 專案動機 *Motivation*

### 1.1 問題背景

資訊爆炸時代，新聞媒體每日產生海量資訊，讀者面臨以下挑戰：

1. **資訊過載** *Information Overload*：熱門事件相關新聞數以千計，難以快速找到核心內容
2. **檢索技術落差**：傳統關鍵字匹配 vs. 現代語義理解，檢索效果差異顯著
3. **缺乏智能分析**：無法自動識別新聞實體、主題分布、事件脈絡
4. **查詢優化困難**：使用者難以精確表達資訊需求，需要系統協助改善查詢

### 1.2 專案目標

本專案旨在建立一個**整合傳統 IR 與現代 NLP 的中文新聞檢索系統**，核心目標：

✅ **技術對比展示**：並列呈現傳統（Boolean, TF-IDF）與現代（BERT 語義檢索）方法的差異
✅ **智能增強檢索**：整合 NER、主題建模、句法分析等 NLP 技術
✅ **查詢優化**：實作 Rocchio、同義詞擴展、中文諧音匹配
✅ **結果智能化**：自動摘要、文檔聚類、相似新聞推薦
✅ **雙介面支援**：CLI（技術展示）+ Web UI（使用者友善）

### 1.3 創新點與特色

**區別於一般搜尋引擎**：

| 維度 | 一般新聞網站 | 本專案系統 |
|------|------------|-----------|
| **檢索模型** | 單一模型（通常 BM25） | 4 種模型並列比較 |
| **NLP 增強** | 無或有限 | 完整整合 NER/主題/句法 |
| **查詢優化** | 簡單自動完成 | Rocchio + 語義擴展 |
| **結果分析** | 僅列表展示 | 摘要 + 聚類 + 視覺化 |
| **技術透明度** | 黑盒 | 開源 + 性能對比報告 |

### 1.4 應用場景

**目標使用者**：
- 研究人員追蹤特定議題新聞
- 新聞編輯室進行資料查證
- 一般讀者快速了解事件全貌

**使用情境範例**：
> 小華想了解「ChatGPT 對教育的影響」，他在系統輸入查詢後：
> 1. **傳統 TF-IDF**：返回包含「ChatGPT」、「教育」關鍵字的新聞
> 2. **BERT 語義檢索**：額外找到「生成式 AI 在校園應用」、「大型語言模型衝擊學習」等語義相關新聞
> 3. **NER 增強**：自動標註相關實體（OpenAI、台大、教育部）
> 4. **主題分群**：將結果分為「政策討論」、「技術應用」、「倫理爭議」三大主題
> 5. **智能摘要**：每組主題提供 3 句話摘要
>
> 小華可一鍵切換不同檢索模型，直觀比較傳統與現代方法的差異。

---

## 2. 系統功能規劃 *Functional Requirements*

### 2.1 核心功能：多模型檢索比較

#### F1: 傳統檢索模型

**F1.1 布林檢索** *Boolean Retrieval*
- 支援 AND/OR/NOT 運算子
- 詞組查詢（位置索引）
- 欄位限定查詢（標題/內容/作者/日期）
- **特點**：精確匹配、無排序

**F1.2 向量空間模型** *Vector Space Model (TF-IDF)*
- TF-IDF 權重計算（多種方案：ltc, lnc）
- 餘弦相似度排序
- 支援查詢詞權重調整
- **特點**：經典排序模型、計算高效

**F1.3 BM25 排序**（待實作）
- Okapi BM25 演算法
- 參數可調（k1, b）
- 文檔長度正規化
- **特點**：工業界標準、效果穩定

#### F2: 現代語義檢索

**F2.1 BERT 語義檢索**
- 使用 `sentence-transformers`（中文模型：`paraphrase-multilingual-MiniLM-L12-v2`）
- 文檔與查詢的 embedding 向量化
- 語義相似度計算（cosine similarity）
- **特點**：語義理解、跨詞匹配

**對比展示介面**：
```
查詢：「颱風災害救援」

┌─────────────────────────────────────────────────────────────┐
│ 模型對比 (前 5 筆)                                            │
├─────────────────────────────────────────────────────────────┤
│ [Boolean] 34 篇符合 → 無排序                                  │
│ [TF-IDF]  相關性分數: 0.82, 0.78, 0.71, 0.68, 0.65          │
│ [BM25]    相關性分數: 15.3, 14.1, 13.8, 12.9, 12.4          │
│ [BERT]    語義分數:   0.89, 0.87, 0.84, 0.81, 0.79          │
├─────────────────────────────────────────────────────────────┤
│ 效能比較:                                                     │
│ - 檢索時間: Boolean(50ms), TF-IDF(120ms), BERT(650ms)        │
│ - 獨特結果: Boolean(12), TF-IDF(8), BERT(15)                 │
│ - MAP: TF-IDF(0.68), BERT(0.75)                              │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 進階 NLP 功能整合

#### F3: 命名實體識別 *Named Entity Recognition (NER)*

**功能**：
- 使用 CKIP Transformers 識別中文實體
- 實體類型：人名（PER）、地名（LOC）、組織（ORG）、時間（TIME）
- 實體過濾檢索：`entity:人名="蔡英文"`
- 實體共現分析：找出新聞中頻繁出現的實體組合

**應用場景**：
```python
# 查詢「台積電」相關新聞
→ 自動識別相關實體：
  - 組織：台積電、TSMC、鴻海
  - 人名：劉德音、魏哲家
  - 地名：新竹、台南、美國亞利桑那
→ 提供實體篩選側邊欄
```

#### F4: 主題建模 *Topic Modeling*

**方法對比**：
- **LDA** (*Latent Dirichlet Allocation*)：傳統機率主題模型
- **BERTopic**：基於 BERT embeddings + UMAP + HDBSCAN

**功能**：
- 自動發現新聞語料的主題分布（5-20 個主題）
- 主題標籤自動命名（基於 top-N 關鍵詞）
- 主題時間序列分析（主題熱度隨時間變化）
- 支援「主題瀏覽」模式（依主題分類查看新聞）

**展示範例**：
```
主題 1: 疫情防控 (12% 文檔)
關鍵詞: 疫苗, 確診, 防疫, 隔離, 口罩
代表新聞: [標題列表...]

主題 2: 經濟政策 (8% 文檔)
關鍵詞: 央行, 升息, 通膨, GDP, 經濟成長
代表新聞: [標題列表...]
```

#### F5: 關鍵詞提取 *Keyword Extraction*

**多演算法整合**：
- **TextRank**：基於圖的無監督方法
- **YAKE**：統計特徵 + 位置權重
- **KeyBERT**：BERT embeddings + MMR 多樣性
- **RAKE**：快速關鍵詞提取

**功能**：
- 每篇新聞自動提取 5-10 個關鍵詞
- 支援關鍵詞雲視覺化（Word Cloud）
- 關鍵詞趨勢分析（時間軸）
- 基於關鍵詞的「相關新聞推薦」

#### F6: 句法分析 *Syntactic Parsing*

**功能**：
- 依存句法分析（SuPar）
- SVO 三元組提取（主謂賓結構）
- 支援結構化查詢：`subject:"政府" verb:"宣布"`

**應用**：
```python
# 查詢「誰宣布了什麼政策？」
→ 句法分析提取 SVO:
  (政府, 宣布, 新政策)
  (教育部, 推動, 雙語教育)
  (央行, 調升, 利率)
→ 結構化展示政策新聞
```

### 2.3 查詢優化功能

#### F7: Rocchio 查詢擴展

**功能**：
- 擬相關回饋（PRF）：假設前 K 筆相關
- 明確回饋：使用者標記相關/不相關文檔
- 動態調整查詢向量（α, β, γ 參數）

**流程**：
```
初始查詢: "人工智慧"
  ↓ [Rocchio 擴展]
擴展查詢: "人工智慧 + 機器學習 + 深度學習 + 神經網路"
  ↓ [重新檢索]
改善後結果: MAP 0.65 → 0.73 (+12%)
```

#### F8: 同義詞與語義擴展

**方法**：
- **靜態同義詞**：基於中文同義詞詞典（如 HowNet）
- **動態擴展**：使用 BERT 找出語義相近詞（cosine similarity > 0.8）
- **中文諧音匹配**：CSoundex 編碼處理同音字（三聚氰胺/三聚氫胺）

**範例**：
```
查詢: "颱風"
同義詞擴展: 颱風, 颶風, 熱帶氣旋, 風災
語義擴展: 暴風, 豪雨, 災害, 停班停課
諧音: 台風 (CSoundex: T200)
```

### 2.4 智能摘要與聚類

#### F9: 自動摘要 *Automatic Summarization*

**靜態摘要**：
- Lead-K：取前 K 句（適合新聞倒金字塔結構）
- 關鍵句萃取：基於 TF-IDF 分數排序

**動態摘要（KWIC）**：
- 查詢詞前後文視窗（50 字符）
- 多查詢詞高亮顯示
- 快取機制（避免重複計算）

**多文檔摘要**：
- 對搜尋結果前 N 篇生成綜合摘要
- 使用 extractive summarization（抽取式）

#### F10: 文檔聚類 *Document Clustering*

**演算法**：
- **K-means**：平面聚類（K=3-10）
- **階層式聚類**：Complete-link（生成主題樹）

**應用**：
- 搜尋結果自動分組（「這些新聞可分為 3 類」）
- 相似新聞推薦（同一聚類的其他新聞）
- 聚類視覺化（2D t-SNE/UMAP 投影）

---

## 3. 技術架構 *Technical Architecture*

### 3.1 系統架構圖

```
┌────────────────────────────────────────────────────────────────┐
│                      使用者介面層 (User Interface)              │
│  ┌──────────────────────┐  ┌──────────────────────────────┐  │
│  │   CLI 工具            │  │   Web UI (Flask + Bootstrap) │  │
│  │  - 批次查詢評估       │  │  - 搜尋框與結果展示          │  │
│  │  - 性能測試           │  │  - 模型對比視覺化            │  │
│  │  - 索引管理           │  │  - 實體/主題互動式篩選       │  │
│  └──────────────────────┘  └──────────────────────────────┘  │
└───────────────────────────┬────────────────────────────────────┘
                            │ REST API / Function Call
┌───────────────────────────▼────────────────────────────────────┐
│                      應用邏輯層 (Application Logic)             │
│  ┌────────────────┐  ┌────────────────┐  ┌─────────────────┐ │
│  │ 查詢路由        │  │ 多模型協調器    │  │ 結果後處理       │ │
│  │ - 解析查詢      │  │ - Boolean      │  │ - 摘要生成       │ │
│  │ - 參數驗證      │  │ - TF-IDF       │  │ - 聚類分析       │ │
│  │ - 結果融合      │  │ - BM25         │  │ - 實體標註       │ │
│  │                 │  │ - BERT Semantic│  │                  │ │
│  └────────────────┘  └────────────────┘  └─────────────────┘ │
│         Flask/FastAPI (Python 3.10+)                            │
└───────────────────────────┬────────────────────────────────────┘
                            │
┌───────────────────────────▼────────────────────────────────────┐
│                      IR 核心層 (IR Core Modules)                │
│  ┌────────────────────────────────────────────────────────┐   │
│  │  傳統 IR 模組 (已實作)                                   │   │
│  │  - inverted_index.py    - positional_index.py          │   │
│  │  - boolean.py           - vsm.py                       │   │
│  │  - term_weighting.py    - rocchio.py                   │   │
│  └────────────────────────────────────────────────────────┘   │
│  ┌────────────────────────────────────────────────────────┐   │
│  │  現代 NLP 模組 (已實作)                                  │   │
│  │  - ner_extractor.py     - lda_model.py                 │   │
│  │  - bertopic_model.py    - textrank.py                  │   │
│  │  - yake_extractor.py    - keybert_extractor.py         │   │
│  │  - parser.py (SuPar)    - chinese_tokenizer.py         │   │
│  └────────────────────────────────────────────────────────┘   │
│  ┌────────────────────────────────────────────────────────┐   │
│  │  新增模組 (待實作)                                       │   │
│  │  - bm25.py              - semantic_search.py (BERT)    │   │
│  │  - multi_model_ranker.py - result_aggregator.py        │   │
│  └────────────────────────────────────────────────────────┘   │
└───────────────────────────┬────────────────────────────────────┘
                            │
┌───────────────────────────▼────────────────────────────────────┐
│                      資料儲存層 (Data Storage)                  │
│  ┌─────────────────┐  ┌──────────────┐  ┌──────────────────┐ │
│  │  新聞資料庫      │  │  索引檔案     │  │  模型檔案         │ │
│  │  (SQLite)       │  │  (JSON/Pkl)  │  │  (HF Models)     │ │
│  │  - 原始內容      │  │  - 倒排索引   │  │  - BERT          │ │
│  │  - 元資料        │  │  - TF-IDF    │  │  - LDA           │ │
│  │  - 已處理欄位    │  │  - Embeddings│  │  - BERTopic      │ │
│  └─────────────────┘  └──────────────┘  └──────────────────┘ │
└────────────────────────────────────────────────────────────────┘
```

### 3.2 技術棧 *Technology Stack*

**後端核心**：
- Python 3.10+
- Flask / FastAPI（Web 框架）
- SQLite（資料庫）

**傳統 IR**（已實作）：
- 自行實作倒排索引、TF-IDF、Rocchio

**現代 NLP**：
- **CKIP Transformers**：中文 NER
- **Sentence-Transformers**：BERT 語義檢索（`paraphrase-multilingual-MiniLM-L12-v2`）
- **Gensim**：LDA 主題建模
- **BERTopic**：現代主題建模
- **SuPar**：依存句法分析
- **Jieba / CKIP**：中文分詞

**前端**：
- HTML5 + Bootstrap 5（響應式）
- Chart.js / Plotly（圖表視覺化）
- jQuery（AJAX 請求）

**評估與測試**：
- Pytest（單元測試）
- 自行實作評估指標（MAP, nDCG）

**部署**：
- Docker（容器化）
- Conda 環境管理

### 3.3 資料結構設計

#### 新聞資料表 (SQLite)

```sql
CREATE TABLE news (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT NOT NULL,                -- 標題
    content TEXT NOT NULL,              -- 內文
    author TEXT,                        -- 作者
    source TEXT,                        -- 來源媒體
    publish_date DATE,                  -- 發布日期
    category TEXT,                      -- 分類（政治/經濟/社會）
    url TEXT UNIQUE,                    -- 原始網址

    -- NLP 預處理欄位
    tokens_title TEXT,                  -- JSON: 標題分詞結果
    tokens_content TEXT,                -- JSON: 內文分詞結果
    entities TEXT,                      -- JSON: NER 實體
    keywords TEXT,                      -- JSON: 關鍵詞
    topic_id INTEGER,                   -- 主題 ID
    summary TEXT,                       -- 自動摘要（3 句）

    -- 索引與檢索
    tfidf_vector TEXT,                  -- JSON: TF-IDF 向量
    bert_embedding TEXT,                -- JSON: BERT embedding (768 維)

    -- 元資料
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_publish_date ON news(publish_date);
CREATE INDEX idx_category ON news(category);
CREATE INDEX idx_topic_id ON news(topic_id);
```

#### 索引結構 (JSON/Pickle)

```python
{
  "inverted_index": {
    "颱風": [
      {"doc_id": 1, "tf": 0.05, "positions": [3, 45]},
      {"doc_id": 5, "tf": 0.03, "positions": [12]}
    ],
    "災害": [...]
  },

  "idf": {
    "颱風": 2.3,  # log(N/df)
    "災害": 1.8
  },

  "doc_norms": {
    "1": 15.6,  # L2 norm for cosine normalization
    "5": 18.2
  },

  "bert_embeddings": {
    "1": [0.12, -0.34, 0.56, ...],  # 768 維向量
    "5": [0.23, -0.12, 0.78, ...]
  }
}
```

---

## 4. 資料來源 *Data Sources*

### 4.1 資料集選擇

**選項 A：公開新聞資料集（推薦）**

**中央社開放資料平台**
- **網址**：https://www.cna.com.tw/postwrite/Data/PilotDataPlatform.aspx
- **規模**：數十萬筆新聞
- **欄位**：標題、內文、分類、日期
- **格式**：JSON / CSV
- **授權**：需確認授權條款

**聯合報系開放資料**
- **來源**：TAIGI 台語文語料庫（含新聞語料）
- **規模**：數萬篇新聞
- **優點**：正體中文、分類完整

**選項 B：自行爬取**

**目標網站**：
- 公視新聞網（https://news.pts.org.tw/）
- 中央社（https://www.cna.com.tw/）
- 自由時報（https://news.ltn.com.tw/）

**技術**：
- Beautiful Soup / Scrapy
- 遵守 robots.txt
- 尊重爬取頻率限制

**選項 C：Common Crawl 新聞語料**

**來源**：Common Crawl News Dataset
- **網址**：https://commoncrawl.org/
- **規模**：PB 級新聞資料
- **優點**：合法、大規模
- **缺點**：需過濾中文資料

### 4.2 本專案資料集規劃

**選擇**：**中央社開放資料 + 公視新聞** （自行爬取）

**規模目標**：
- 新聞數量：**30,000 - 50,000 篇**
- 時間範圍：**2022-2024 年**（3 年）
- 分類涵蓋：政治、經濟、社會、國際、科技、生活

**資料清理流程**：

```python
def preprocess_news(raw_news):
    """
    新聞資料前處理流程。

    步驟:
    1. 去除 HTML 標籤與特殊符號
    2. 正規化空白與換行
    3. 日期格式統一 (YYYY-MM-DD)
    4. 去除重複新聞（基於標題相似度）
    5. 分詞與 NER 處理
    6. 關鍵詞提取
    7. 儲存至資料庫

    Returns:
        processed_news (dict): 清理後的新聞資料
    """
    # Implementation
    pass
```

### 4.3 資料統計與分析

**預期資料分布**：

| 分類 | 比例 | 約篇數 |
|------|------|--------|
| 政治 | 25% | 12,500 |
| 經濟 | 20% | 10,000 |
| 社會 | 20% | 10,000 |
| 國際 | 15% | 7,500 |
| 科技 | 10% | 5,000 |
| 生活 | 10% | 5,000 |

**時間分布**：
- 2022年：15,000 篇
- 2023年：18,000 篇
- 2024年：17,000 篇

---

## 5. 評估計畫 *Evaluation Plan*

### 5.1 定量評估

#### 5.1.1 檢索品質指標

**測試集建構**：
- 人工標註 **50 個查詢**（涵蓋不同主題與困難度）
- 每個查詢標註前 20 筆結果（4 級相關性：0=不相關, 1=勉強相關, 2=相關, 3=高度相關）

**評估指標**：

| 指標 | 公式 | 目標值 |
|------|------|--------|
| **MAP** | Mean Average Precision | > 0.70 |
| **nDCG@10** | Normalized DCG (top-10) | > 0.75 |
| **P@5** | Precision at 5 | > 0.80 |
| **MRR** | Mean Reciprocal Rank | > 0.70 |

**模型對比表**：

| 模型 | MAP | nDCG@10 | P@5 | 查詢延遲 (ms) |
|------|-----|---------|-----|--------------|
| Boolean | - | - | - | 50 |
| TF-IDF | 0.68 | 0.72 | 0.75 | 120 |
| BM25 | 0.72 | 0.76 | 0.80 | 130 |
| BERT Semantic | **0.79** | **0.83** | **0.85** | 680 |

*（數值為預期目標，實際需實驗驗證）*

#### 5.1.2 效能指標

**系統效能**：

| 指標 | 測試條件 | 目標 |
|------|---------|------|
| 索引建構時間 | 50,000 篇新聞 | < 10 分鐘 |
| 索引檔案大小 | 50,000 篇新聞 | < 5 GB |
| 查詢延遲 (P95) | 單查詢 | < 1 秒 |
| BERT 延遲 | 單查詢 | < 2 秒 |
| 記憶體使用 | 運行時 | < 8 GB |

#### 5.1.3 NLP 功能評估

**NER 準確度**：
- 在 100 篇手動標註的新聞上測試
- F1-score > 0.85（實體識別）

**主題建模**：
- 主題一致性（Coherence Score）
- 人工評估主題可解釋性（5 位評估者）

**關鍵詞提取**：
- 與人工標註關鍵詞比較
- F1-score > 0.70

**摘要品質**：
- ROUGE-L > 0.40（與人工摘要比較）

### 5.2 定性評估

#### 5.2.1 案例研究

**選擇 5 個具代表性的查詢**，進行深度分析：

**案例 1：簡單事實查詢**
- 查詢：「2024 總統大選結果」
- 分析：比較各模型是否返回正確的選舉新聞

**案例 2：語義理解查詢**
- 查詢：「綠能政策爭議」
- 分析：BERT 是否能找到「再生能源」、「碳中和」等語義相關新聞

**案例 3：實體關係查詢**
- 查詢：「蔡英文訪問美國」
- 分析：NER 是否正確識別「蔡英文」（人名）、「美國」（地名）

**案例 4：複雜主題查詢**
- 查詢：「AI 對就業市場的影響」
- 分析：主題建模是否能分群出不同觀點（樂觀/悲觀）

**案例 5：時效性查詢**
- 查詢：「近期颱風災情」
- 分析：日期權重是否正確提升最新新聞的排名

#### 5.2.2 使用者研究（選做）

**招募**：5-8 位測試者（同學或朋友）

**任務設計**：
1. 自由查詢（5 分鐘）：讓使用者輸入感興趣的查詢
2. 指定任務（3 個）：找出特定資訊（如「2023 年最受關注的科技新聞」）
3. 模型比較：讓使用者評分 4 種模型的結果（1-5 分）

**問卷調查**：
- 系統易用性（System Usability Scale, SUS）
- 各模型偏好排序
- 開放式意見回饋

---

## 6. 工作時程 *Project Timeline*

**總工期**：6 週（Week 1 - Week 6）

| 週次 | 主要任務 | 具體工作 | 交付成果 |
|------|---------|---------|---------|
| **Week 1** | 資料準備與環境建置 | - 資料集收集（爬取/下載）<br>- 資料清理與統一格式<br>- 環境配置（Conda, 依賴套件） | - 50,000 篇新聞資料<br>- 資料統計報告 |
| **Week 2** | 索引建構與傳統檢索 | - 建立倒排索引與位置索引<br>- 實作 TF-IDF, BM25<br>- NLP 預處理（分詞, NER） | - 索引檔案<br>- Boolean, TF-IDF 可查詢 |
| **Week 3** | 現代 NLP 整合 | - BERT 語義檢索實作<br>- 主題建模（LDA, BERTopic）<br>- 關鍵詞提取整合 | - BERT 檢索功能<br>- 主題分群結果 |
| **Week 4** | 系統開發 | - 後端 API 開發（Flask）<br>- 多模型協調器<br>- CLI 工具完善<br>- Web UI 開發 | - RESTful API<br>- CLI 工具<br>- Web 原型 |
| **Week 5** | 評估與優化 | - 建立測試集（50 queries）<br>- 效能評估（MAP, nDCG）<br>- 效能調校與 bug 修復 | - 評估報告<br>- 效能對比表 |
| **Week 6** | 文件與展示 | - 撰寫期末報告<br>- 準備展示簡報<br>- 錄製 Demo 影片 | - 最終報告 (PDF)<br>- 簡報 (PPT)<br>- Demo 影片 |

**里程碑檢查點**：
- ✅ **Week 2**：索引建構完成，可執行基本查詢
- ✅ **Week 4**：系統可運行（MVP），Web UI 可展示
- ✅ **Week 6**：完整系統 + 評估報告

---

## 7. 風險評估與應對 *Risk Management*

| 風險 | 可能性 | 影響 | 應對策略 |
|------|--------|------|---------|
| **資料集授權問題** | 中 | 高 | 優先使用公開資料集；若需爬取，遵守 robots.txt 並標註來源 |
| **BERT 模型運算太慢** | 高 | 中 | 使用 MiniLM（小型模型）；批次預計算 embeddings；GPU 加速 |
| **資料清理耗時** | 高 | 中 | 使用既有的清理工具（BeautifulSoup）；並行處理 |
| **NLP 模型整合困難** | 中 | 中 | 使用現成函式庫（Transformers, SuPar）；參考官方範例 |
| **評估標註成本高** | 高 | 低 | 縮小測試集至 30-50 queries；邀請 2-3 位同學協助標註 |
| **Web UI 開發延遲** | 中 | 低 | 使用 Bootstrap 模板；優先完成核心功能，UI 簡化 |
| **時程壓力** | 高 | 高 | 每週固定進度檢查；優先完成核心功能，進階功能選做 |

**應變計畫**：
- 若 BERT 效能不佳：降級為僅使用 Sentence-BERT（不需 GPU）
- 若資料集不足：降低規模至 10,000-20,000 篇
- 若時間不足：砍掉選做功能（引用網路視覺化、使用者研究）

---

## 8. 期望成果 *Expected Deliverables*

### 8.1 系統交付物

**1. 可運行的檢索系統**
- **CLI 工具**：支援批次查詢、效能測試、索引管理
- **Web 應用**：搜尋介面 + 結果展示 + 模型對比
- **部署方式**：Docker 容器化，可在本機或雲端運行

**2. 原始碼與文件**
- **GitHub Repository**（公開）
- **README.md**：安裝指南、使用說明、API 文件
- **技術文件**：架構設計、模組說明、資料格式
- **程式碼品質**：
  - 註解率 > 80%
  - 單元測試覆蓋率 > 70%
  - PEP 8 代碼風格

**3. 評估報告**
- **定量分析**：MAP, nDCG, P@K 等指標表格
- **定性分析**：案例研究、錯誤分析、使用者反饋
- **模型對比**：4 種檢索模型的詳細比較

**4. 展示材料**
- **期末報告**：15-20 頁 PDF（詳見第 9 節格式要求）
- **展示簡報**：10 分鐘 PPT
- **Demo 影片**：5-8 分鐘系統操作演示（錄影）

### 8.2 學術與教學價值

**技術貢獻**：
- ✅ 中文新聞檢索的開源實作
- ✅ 傳統 IR vs. 現代 NLP 的實證比較
- ✅ 整合多種 NLP 技術的完整範例

**教學資源**：
- 可作為 IR 課程的教學案例
- 提供完整的中文文檔與註解
- 模組化設計，便於擴展與學習

---

## 9. 參考文獻 *References*

[1] Manning, C. D., Raghavan, P., & Schütze, H. (2008). *Introduction to Information Retrieval*. Cambridge University Press.

[2] Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding*. NAACL.

[3] Reimers, N., & Gurevych, I. (2019). *Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks*. EMNLP.

[4] Grootendorst, M. (2022). *BERTopic: Neural topic modeling with a class-based TF-IDF procedure*. arXiv preprint arXiv:2203.05794.

[5] CKIP Transformers. https://github.com/ckiplab/ckip-transformers

[6] Sentence Transformers Documentation. https://www.sbert.net/

[7] 中央社開放資料平台. https://www.cna.com.tw/

---

## 10. 附錄：功能優先級

### Must-Have（必須完成）
- ✅ 倒排索引與布林檢索
- ✅ TF-IDF + VSM 排序
- ✅ BERT 語義檢索
- ✅ NER 實體識別
- ✅ CLI 工具
- ✅ 基本 Web UI
- ✅ 評估指標計算

### Should-Have（應該完成）
- ✅ BM25 排序
- ✅ 主題建模（LDA + BERTopic）
- ✅ 關鍵詞提取（TextRank + KeyBERT）
- ✅ 查詢擴展（Rocchio）
- ✅ 自動摘要
- ✅ 文檔聚類

### Nice-to-Have（時間許可）
- 句法分析（SVO 三元組）
- 同義詞擴展
- 引用網路視覺化
- 使用者研究
- 多文檔摘要

---

**提案人簽名**：________________
**指導教師核准**：________________
**日期**：2025-01-13

---

**最後更新**: 2025-01-13
**版本**: 2.0 (從學術論文改版為新聞檢索系統)
